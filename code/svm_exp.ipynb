{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation with Non-DL SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from modules.data_loader import load_initial_data\n",
    "from modules.text_segmentation import tokenize_text, handle_unusual_sentences\n",
    "from modules.text_normalization import normalize_text\n",
    "from modules.connlu_converter import convert_to_connlu\n",
    "from modules.utils import setup_logging\n",
    "import logging\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:40,662 - __main__ - INFO - Loading initial data...\n",
      "2024-12-13 21:44:43,030 - __main__ - INFO - Loaded 198 documents\n",
      "2024-12-13 21:44:43,031 - __main__ - INFO - Tokenizing text...\n",
      "2024-12-13 21:44:44,104 - __main__ - INFO - Handling unusual sentences...\n",
      "2024-12-13 21:44:44,106 - __main__ - INFO - Normalizing text...\n",
      "2024-12-13 21:44:44,107 - modules.text_normalization - INFO - Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44,125 - stanza - INFO - Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44 INFO: Using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44,127 - stanza - INFO - Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44 INFO: Loading: tokenize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44,129 - stanza - INFO - Loading: tokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44 INFO: Loading: lemma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:44,131 - stanza - INFO - Loading: lemma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\stanza\\models\\lemma\\trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-13 21:44:46 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:44:46,202 - stanza - INFO - Done loading processors!\n",
      "2024-12-13 21:44:46,234 - modules.text_normalization - INFO - Starting processing of 198 rows in 4 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing text: 100%|██████████| 4/4 [00:16<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:45:02,689 - __main__ - INFO - Preprocessing completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "setup_logging()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths\n",
    "if '__file__' in globals():\n",
    "    base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    base_path = os.getcwd()\n",
    "documents_path = os.path.join(base_path, \"../training_data_16_October_release/EN/raw-documents\")\n",
    "annotations_file = os.path.join(base_path, \"../training_data_16_October_release/EN/subtask-2-annotations.txt\")\n",
    "output_dir = os.path.join(base_path, \"../CoNLL\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# 1. Load and prepare initial data\n",
    "logger.info(\"Loading initial data...\")\n",
    "df = load_initial_data(documents_path, annotations_file)\n",
    "logger.info(f\"Loaded {len(df)} documents\")\n",
    "\n",
    "# 2. Tokenize text\n",
    "logger.info(\"Tokenizing text...\")\n",
    "df = tokenize_text(df)\n",
    "\n",
    "# 3. Handle unusual sentences\n",
    "logger.info(\"Handling unusual sentences...\")\n",
    "df = handle_unusual_sentences(df)\n",
    "\n",
    "# 4. Normalize text\n",
    "logger.info(\"Normalizing text...\")\n",
    "df = normalize_text(df)\n",
    "# print(df.head())\n",
    "# print(df.columns)\n",
    "# print(type(df['tokens_normalized'].iloc[0]))\n",
    "# print(df['tokens_normalized'].iloc[0])\n",
    "# print(df['narrative_subnarrative_pairs'].iloc[0])\n",
    "# 5. Convert to CoNLL-U format\n",
    "# only use when ConLL-U format is needed\n",
    "#logger.info(\"Converting to CoNLL-U format...\")\n",
    "#convert_to_connlu(df, output_dir, 'tokens')\n",
    "logger.info(\"Preprocessing completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "      <th>narrative_subnarrative_pairs</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN_UA_103861.txt</td>\n",
       "      <td>The World Needs Peacemaker Trump Again \\n\\n by...</td>\n",
       "      <td>UA</td>\n",
       "      <td>[{'narrative': 'Other', 'subnarrative': 'Other'}]</td>\n",
       "      <td>[[The, World, Needs, Peacemaker, Trump, Again,...</td>\n",
       "      <td>[world, need, peacemaker, trump, jeff, crouere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN_UA_103667.txt</td>\n",
       "      <td>Desperation and Diplomacy: North Korea's Tech ...</td>\n",
       "      <td>UA</td>\n",
       "      <td>[{'narrative': 'Other', 'subnarrative': 'Other'}]</td>\n",
       "      <td>[[Desperation, and, Diplomacy, :, North, Korea...</td>\n",
       "      <td>[desperation, diplomacy, north, korea, tech, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN_UA_021270.txt</td>\n",
       "      <td>Ukraine's Fate Will Be Decided In Coming Year,...</td>\n",
       "      <td>UA</td>\n",
       "      <td>[{'narrative': 'Speculating war outcomes', 'su...</td>\n",
       "      <td>[[Ukraine, 's, Fate, Will, Be, Decided, In, Co...</td>\n",
       "      <td>[ukraine, fate, decide, come, year, top, zelen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN_UA_103403.txt</td>\n",
       "      <td>Russia Stages Major Airstrike on Ukraine; One ...</td>\n",
       "      <td>UA</td>\n",
       "      <td>[{'narrative': 'Other', 'subnarrative': 'Other'}]</td>\n",
       "      <td>[[Russia, Stages, Major, Airstrike, on, Ukrain...</td>\n",
       "      <td>[russia, stage, major, airstrike, ukraine, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN_CC_100145.txt</td>\n",
       "      <td>Strategy needed to preserve water resources in...</td>\n",
       "      <td>CC</td>\n",
       "      <td>[{'narrative': 'Other', 'subnarrative': 'Other'}]</td>\n",
       "      <td>[[Strategy, needed, to, preserve, water, resou...</td>\n",
       "      <td>[strategy, need, preserve, water, resource, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                                            content topic  \\\n",
       "0  EN_UA_103861.txt  The World Needs Peacemaker Trump Again \\n\\n by...    UA   \n",
       "1  EN_UA_103667.txt  Desperation and Diplomacy: North Korea's Tech ...    UA   \n",
       "2  EN_UA_021270.txt  Ukraine's Fate Will Be Decided In Coming Year,...    UA   \n",
       "3  EN_UA_103403.txt  Russia Stages Major Airstrike on Ukraine; One ...    UA   \n",
       "4  EN_CC_100145.txt  Strategy needed to preserve water resources in...    CC   \n",
       "\n",
       "                        narrative_subnarrative_pairs  \\\n",
       "0  [{'narrative': 'Other', 'subnarrative': 'Other'}]   \n",
       "1  [{'narrative': 'Other', 'subnarrative': 'Other'}]   \n",
       "2  [{'narrative': 'Speculating war outcomes', 'su...   \n",
       "3  [{'narrative': 'Other', 'subnarrative': 'Other'}]   \n",
       "4  [{'narrative': 'Other', 'subnarrative': 'Other'}]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [[The, World, Needs, Peacemaker, Trump, Again,...   \n",
       "1  [[Desperation, and, Diplomacy, :, North, Korea...   \n",
       "2  [[Ukraine, 's, Fate, Will, Be, Decided, In, Co...   \n",
       "3  [[Russia, Stages, Major, Airstrike, on, Ukrain...   \n",
       "4  [[Strategy, needed, to, preserve, water, resou...   \n",
       "\n",
       "                                   tokens_normalized  \n",
       "0  [world, need, peacemaker, trump, jeff, crouere...  \n",
       "1  [desperation, diplomacy, north, korea, tech, h...  \n",
       "2  [ukraine, fate, decide, come, year, top, zelen...  \n",
       "3  [russia, stage, major, airstrike, ukraine, one...  \n",
       "4  [strategy, need, preserve, water, resource, pa...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_mapping(all_narratives):\n",
    "    \"\"\"\n",
    "    Create a consistent mapping for all narrative pairs\n",
    "    \n",
    "    Args:\n",
    "        all_narratives: List of lists of narrative dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from narrative string to numeric index\n",
    "    \"\"\"\n",
    "    unique_narratives = set()\n",
    "    for narratives in all_narratives:\n",
    "        for narrative in narratives:\n",
    "            narrative_str = str(narrative)  # Convert dict to string\n",
    "            unique_narratives.add(narrative_str)\n",
    "    \n",
    "    # Create mapping\n",
    "    narrative_to_idx = {\n",
    "        narrative: idx \n",
    "        for idx, narrative in enumerate(sorted(unique_narratives))\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Created mapping for {len(narrative_to_idx)} unique narratives\")\n",
    "    return narrative_to_idx\n",
    "\n",
    "def get_first_narrative_label(narrative_list, label_mapping):\n",
    "    \"\"\"\n",
    "    Convert first narrative in list to numeric label\n",
    "    \n",
    "    Args:\n",
    "        narrative_list: List of narrative dictionaries\n",
    "        label_mapping: Dictionary mapping narrative strings to indices\n",
    "    \n",
    "    Returns:\n",
    "        int: Numeric label for the first narrative\n",
    "    \"\"\"\n",
    "    if narrative_list and len(narrative_list) > 0:\n",
    "        narrative_str = str(narrative_list[0])\n",
    "        return label_mapping[narrative_str]\n",
    "    return None\n",
    "\n",
    "def prepare_data(df, label_mapping=None):\n",
    "    \"\"\"\n",
    "    Prepare data for BERT training\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing tokens_normalized and narrative_subnarrative_pairs\n",
    "        label_mapping: Optional pre-existing label mapping to use\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (texts, labels, label_mapping)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle tokens_normalized\n",
    "        texts = df['tokens_normalized'].tolist()\n",
    "        texts = [' '.join(tokens) if isinstance(tokens, list) else tokens for tokens in texts]\n",
    "        \n",
    "        # Convert narrative_subnarrative_pairs to list if it's a string\n",
    "        narratives = df['narrative_subnarrative_pairs'].apply(\n",
    "            lambda x: eval(x) if isinstance(x, str) else x\n",
    "        ).tolist()\n",
    "\n",
    "        # Create or use label mapping\n",
    "        if label_mapping is None:\n",
    "            label_mapping = create_label_mapping(narratives)\n",
    "            \n",
    "        # Convert narratives to numerical labels\n",
    "        labels = []\n",
    "        for narrative_list in narratives:\n",
    "            if narrative_list:  # Check if list is not empty\n",
    "                label_str = str(narrative_list[0])  # Convert first narrative dict to string\n",
    "                if label_str in label_mapping:\n",
    "                    labels.append(label_mapping[label_str])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown narrative: {label_str}\")\n",
    "            else:\n",
    "                raise ValueError(\"Empty narrative list found\")\n",
    "\n",
    "        logger.info(f\"Number of unique labels in mapping: {len(label_mapping)}\")\n",
    "        logger.info(f\"Sample text: {texts[0][:100]}\")\n",
    "        logger.info(f\"Sample label: {labels[0]}\")\n",
    "        \n",
    "        return texts, labels, label_mapping\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in prepare_data: {str(e)}\")\n",
    "        logger.error(f\"Sample narrative_subnarrative_pairs: {df['narrative_subnarrative_pairs'].iloc[0]}\")\n",
    "        raise\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics\n",
    "    \n",
    "    Args:\n",
    "        pred: Prediction object from trainer\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing computed metrics\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(df, base_path, project_name=\"svm-training\"):\n",
    "    \"\"\"\n",
    "    Train an SVM model for multiclass multilabel classification.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the training data.\n",
    "        base_path: Base path for saving model outputs.\n",
    "        project_name: Name for the project (for logging, optional).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Classification report.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create label mapping\n",
    "        all_narratives = df['narrative_subnarrative_pairs'].apply(\n",
    "            lambda x: eval(x) if isinstance(x, str) else x\n",
    "        ).tolist()\n",
    "        label_mapping = create_label_mapping(all_narratives)\n",
    "        \n",
    "        # Prepare data\n",
    "        train_texts, train_labels, label_mapping = prepare_data(df, label_mapping)\n",
    "        \n",
    "        # Vectorize text using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        X = vectorizer.fit_transform(train_texts)\n",
    "        y = train_labels\n",
    "        #print(y)\n",
    "        # Train SVM using OneVsRestClassifier\n",
    "        model = OneVsRestClassifier(LinearSVC())\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Save vectorizer and model\n",
    "        model_path = os.path.join(base_path, \"svm_model.joblib\")\n",
    "        vectorizer_path = os.path.join(base_path, \"tfidf_vectorizer.joblib\")\n",
    "        joblib.dump(model, model_path)\n",
    "        joblib.dump(vectorizer, vectorizer_path)\n",
    "        \n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "        logger.info(f\"Vectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = model.predict(X)\n",
    "        #print(y_pred)\n",
    "        report = classification_report(y, y_pred, output_dict=True)\n",
    "        logger.info(\"Training classification report:\")\n",
    "        logger.info(json.dumps(report, indent=2))\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in SVM training: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm(text, model_path, vectorizer_path):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained SVM model.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify.\n",
    "        model_path: Path to the saved SVM model.\n",
    "        vectorizer_path: Path to the saved TF-IDF vectorizer.\n",
    "    \n",
    "    Returns:\n",
    "        list: Predicted class indices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and vectorizer\n",
    "        model = joblib.load(model_path)\n",
    "        vectorizer = joblib.load(vectorizer_path)\n",
    "        \n",
    "        # Load label mapping\n",
    "        with open(os.path.join(os.path.dirname(model_path), \"label_mapping.json\"), 'r') as f:\n",
    "            label_mapping = json.load(f)\n",
    "        \n",
    "        # Convert label indices to their original labels\n",
    "        idx_to_label = {v: k for k, v in label_mapping.items()}\n",
    "        \n",
    "        # Transform input text using vectorizer\n",
    "        X = vectorizer.transform([text])\n",
    "        \n",
    "        # Predict\n",
    "        predictions = model.predict(X)[0]\n",
    "        predicted_labels = [idx_to_label[idx] for idx in range(len(predictions)) if predictions[idx] == 1]\n",
    "        print(predicted_labels)\n",
    "        return predicted_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in SVM prediction: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:53:25,493 - __main__ - INFO - Starting BERT training...\n",
      "2024-12-13 21:54:31,328 - __main__ - INFO - Created mapping for 69 unique narratives\n",
      "2024-12-13 21:55:07,905 - __main__ - INFO - Number of unique labels in mapping: 69\n",
      "2024-12-13 21:55:07,905 - __main__ - INFO - Sample text: world need peacemaker trump jeff crouere liberty daily world total chaos month biden presidency sout\n",
      "2024-12-13 21:55:07,911 - __main__ - INFO - Sample label: 49\n",
      "2024-12-13 22:03:33,372 - __main__ - INFO - Model saved to c:\\Users\\leonb\\OneDrive\\Dokumente\\Studium\\Master\\Sem1\\NLP and InfExt\\practical\\nlp_Backpropagandists_2024\\code\\svm_model.joblib\n",
      "2024-12-13 22:03:33,845 - __main__ - INFO - Vectorizer saved to c:\\Users\\leonb\\OneDrive\\Dokumente\\Studium\\Master\\Sem1\\NLP and InfExt\\practical\\nlp_Backpropagandists_2024\\code\\tfidf_vectorizer.joblib\n",
      "2024-12-13 22:20:38,500 - __main__ - INFO - Training classification report:\n",
      "2024-12-13 22:20:38,503 - __main__ - INFO - {\n",
      "  \"0\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 6.0\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 7.0\n",
      "  },\n",
      "  \"8\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"12\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"15\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"16\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"17\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"20\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"21\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 6.0\n",
      "  },\n",
      "  \"22\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"23\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"24\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"25\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"27\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"30\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"31\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"33\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"34\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"35\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"36\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"38\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 6.0\n",
      "  },\n",
      "  \"41\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"43\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"45\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"47\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"49\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 97.0\n",
      "  },\n",
      "  \"50\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"54\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"55\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"57\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"61\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"63\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"65\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"66\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"67\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"68\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"accuracy\": 1.0,\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 198.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 198.0\n",
      "  }\n",
      "}\n",
      "2024-12-13 22:20:38,503 - __main__ - INFO - BERT training completed. Results: {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '4': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, '5': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 7.0}, '8': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '12': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '15': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '16': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '17': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '20': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '21': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, '22': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '23': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '24': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '25': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '27': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '30': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '31': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '33': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '34': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '35': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '36': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '38': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, '41': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '43': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '45': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '47': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '49': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 97.0}, '50': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '54': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '55': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '57': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '61': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '63': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '65': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '66': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '67': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '68': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 198.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 198.0}}\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting BERT training...\")\n",
    "training_results = train_svm(df, base_path)\n",
    "logger.info(f\"BERT training completed. Results: {training_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[49, 49, 66, 49, 49, 49, 4, 49, 35, 49, 49, 15, 38, 67, 55, 3, 49, 49, 33, 49, 49, 49, 47, 49, 66, 31, 12, 49, 49, 12, 49, 38, 49, 49, 49, 49, 66, 49, 24, 49, 67, 30, 49, 23, 49, 49, 34, 5, 49, 49, 49, 49, 49, 49, 36, 22, 49, 22, 35, 47, 49, 38, 2, 49, 49, 49, 61, 31, 5, 49, 38, 49, 50, 54, 49, 5, 0, 31, 31, 49, 8, 0, 49, 21, 49, 68, 49, 21, 35, 67, 49, 49, 49, 49, 49, 49, 45, 27, 49, 49, 5, 4, 49, 49, 49, 47, 49, 25, 49, 49, 49, 49, 49, 4, 68, 24, 49, 30, 3, 17, 49, 49, 33, 49, 49, 49, 49, 49, 49, 4, 30, 45, 21, 38, 16, 49, 5, 49, 30, 49, 49, 61, 45, 49, 50, 4, 3, 49, 22, 49, 49, 50, 49, 49, 57, 20, 12, 33, 49, 5, 49, 49, 49, 49, 49, 49, 49, 36, 2, 3, 17, 49, 12, 38, 49, 2, 36, 21, 43, 4, 49, 67, 49, 15, 63, 49, 65, 41, 49, 21, 47, 21, 49, 63, 49, 2, 5, 49]\n",
    "[49 49 66 49 49 49  4 49 35 49 49 15 38 67 55  3 49 49 33 49 49 49 47 49\n",
    " 66 31 12 49 49 12 49 38 49 49 49 49 66 49 24 49 67 30 49 23 49 49 34  5\n",
    " 49 49 49 49 49 49 36 22 49 22 35 47 49 38  2 49 49 49 61 31  5 49 38 49\n",
    " 50 54 49  5  0 31 31 49  8  0 49 21 49 68 49 21 35 67 49 49 49 49 49 49\n",
    " 45 27 49 49  5  4 49 49 49 47 49 25 49 49 49 49 49  4 68 24 49 30  3 17\n",
    " 49 49 33 49 49 49 49 49 49  4 30 45 21 38 16 49  5 49 30 49 49 61 45 49\n",
    " 50  4  3 49 22 49 49 50 49 49 57 20 12 33 49  5 49 49 49 49 49 49 49 36\n",
    "  2  3 17 49 12 38 49  2 36 21 43  4 49 67 49 15 63 49 65 41 49 21 47 21\n",
    " 49 63 49  2  5 49]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
