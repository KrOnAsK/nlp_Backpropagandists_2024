{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation with Non-DL SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from modules.data_loader import load_initial_data\n",
    "from modules.text_segmentation import tokenize_text, handle_unusual_sentences\n",
    "from modules.text_normalization import normalize_text\n",
    "from modules.connlu_converter import convert_to_connlu\n",
    "from modules.utils import setup_logging\n",
    "import logging\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:34,730 - __main__ - INFO - Loading initial data...\n",
      "2024-12-14 16:02:34,973 - __main__ - INFO - Loaded 198 documents\n",
      "2024-12-14 16:02:34,973 - __main__ - INFO - Tokenizing text...\n",
      "2024-12-14 16:02:36,050 - __main__ - INFO - Handling unusual sentences...\n",
      "2024-12-14 16:02:36,052 - __main__ - INFO - Normalizing text...\n",
      "2024-12-14 16:02:36,052 - modules.text_normalization - INFO - Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36,062 - stanza - INFO - Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36 INFO: Using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36,072 - stanza - INFO - Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36 INFO: Loading: tokenize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36,074 - stanza - INFO - Loading: tokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36 INFO: Loading: lemma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:36,076 - stanza - INFO - Loading: lemma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\stanza\\models\\lemma\\trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-12-14 16:02:38 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:38,414 - stanza - INFO - Done loading processors!\n",
      "2024-12-14 16:02:38,424 - modules.text_normalization - INFO - Starting processing of 198 rows in 4 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing text: 100%|██████████| 4/4 [00:15<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:54,283 - __main__ - INFO - Preprocessing completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "setup_logging()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths\n",
    "if '__file__' in globals():\n",
    "    base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    base_path = os.getcwd()\n",
    "documents_path = os.path.join(base_path, \"../training_data_16_October_release/EN/raw-documents\")\n",
    "annotations_file = os.path.join(base_path, \"../training_data_16_October_release/EN/subtask-2-annotations.txt\")\n",
    "output_dir = os.path.join(base_path, \"../CoNLL\")\n",
    "model_path = os.path.join(base_path, \"./models/svm_model.joblib\")\n",
    "\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# 1. Load and prepare initial data\n",
    "logger.info(\"Loading initial data...\")\n",
    "df = load_initial_data(documents_path, annotations_file)\n",
    "logger.info(f\"Loaded {len(df)} documents\")\n",
    "\n",
    "# 2. Tokenize text\n",
    "logger.info(\"Tokenizing text...\")\n",
    "df = tokenize_text(df)\n",
    "\n",
    "# 3. Handle unusual sentences\n",
    "logger.info(\"Handling unusual sentences...\")\n",
    "df = handle_unusual_sentences(df)\n",
    "\n",
    "# 4. Normalize text\n",
    "logger.info(\"Normalizing text...\")\n",
    "df, df_ua, df_cc = normalize_text(df)\n",
    "# print(df.head())\n",
    "# print(df.columns)\n",
    "# print(type(df['tokens_normalized'].iloc[0]))\n",
    "# print(df['tokens_normalized'].iloc[0])\n",
    "# print(df['narrative_subnarrative_pairs'].iloc[0])\n",
    "# 5. Convert to CoNLL-U format\n",
    "# only use when ConLL-U format is needed\n",
    "#logger.info(\"Converting to CoNLL-U format...\")\n",
    "#convert_to_connlu(df, output_dir, 'tokens')\n",
    "logger.info(\"Preprocessing completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 6) (72, 6) (198, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_ua.shape, df_cc.shape, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_mapping(all_narratives):\n",
    "    \"\"\"\n",
    "    Create a consistent mapping for all narrative pairs\n",
    "    \n",
    "    Args:\n",
    "        all_narratives: List of lists of narrative dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from narrative string to numeric index\n",
    "    \"\"\"\n",
    "    unique_narratives = set()\n",
    "    for narratives in all_narratives:\n",
    "        for narrative in narratives:\n",
    "            narrative_str = str(narrative)  # Convert dict to string\n",
    "            unique_narratives.add(narrative_str)\n",
    "    \n",
    "    # Create mapping\n",
    "    narrative_to_idx = {\n",
    "        narrative: idx \n",
    "        for idx, narrative in enumerate(sorted(unique_narratives))\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Created mapping for {len(narrative_to_idx)} unique narratives\")\n",
    "    return narrative_to_idx\n",
    "\n",
    "def get_first_narrative_label(narrative_list, label_mapping):\n",
    "    \"\"\"\n",
    "    Convert first narrative in list to numeric label\n",
    "    \n",
    "    Args:\n",
    "        narrative_list: List of narrative dictionaries\n",
    "        label_mapping: Dictionary mapping narrative strings to indices\n",
    "    \n",
    "    Returns:\n",
    "        int: Numeric label for the first narrative\n",
    "    \"\"\"\n",
    "    if narrative_list and len(narrative_list) > 0:\n",
    "        narrative_str = str(narrative_list[0])\n",
    "        return label_mapping[narrative_str]\n",
    "    return None\n",
    "\n",
    "def prepare_data(df, label_mapping=None):\n",
    "    \"\"\"\n",
    "    Prepare data for BERT training\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing tokens_normalized and narrative_subnarrative_pairs\n",
    "        label_mapping: Optional pre-existing label mapping to use\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (texts, labels, label_mapping)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle tokens_normalized\n",
    "        texts = df['tokens_normalized'].tolist()\n",
    "        texts = [' '.join(tokens) if isinstance(tokens, list) else tokens for tokens in texts]\n",
    "        \n",
    "        # Convert narrative_subnarrative_pairs to list if it's a string\n",
    "        narratives = df['narrative_subnarrative_pairs'].apply(\n",
    "            lambda x: eval(x) if isinstance(x, str) else x\n",
    "        ).tolist()\n",
    "\n",
    "        # Create or use label mapping\n",
    "        if label_mapping is None:\n",
    "            label_mapping = create_label_mapping(narratives)\n",
    "            \n",
    "        # Convert narratives to binary indicator format for multilabel classification\n",
    "        n_classes = len(label_mapping)\n",
    "        labels = []\n",
    "        for narrative_list in narratives:\n",
    "            label_vector = [0] * n_classes\n",
    "            for narrative in narrative_list:\n",
    "                narrative_str = str(narrative)  # Convert narrative dict to string\n",
    "                if narrative_str in label_mapping:\n",
    "                    label_vector[label_mapping[narrative_str]] = 1\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown narrative: {narrative_str}\")\n",
    "            labels.append(label_vector)\n",
    "\n",
    "        logger.info(f\"Number of unique labels in mapping: {len(label_mapping)}\")\n",
    "        logger.info(f\"Sample text: {texts[0][:100]}\")\n",
    "        logger.info(f\"Sample label: {labels[0]}\")\n",
    "        \n",
    "        return texts, labels, label_mapping\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in prepare_data: {str(e)}\")\n",
    "        logger.error(f\"Sample narrative_subnarrative_pairs: {df['narrative_subnarrative_pairs'].iloc[0]}\")\n",
    "        raise\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics\n",
    "    \n",
    "    Args:\n",
    "        pred: Prediction object from trainer\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing computed metrics\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(df, base_path, project_name=\"svm-training\"):\n",
    "    \"\"\"\n",
    "    Train an SVM model for multiclass multilabel classification.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the training data.\n",
    "        base_path: Base path for saving model outputs.\n",
    "        project_name: Name for the project (for logging, optional).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Classification report.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create label mapping\n",
    "        all_narratives = df['narrative_subnarrative_pairs'].apply(\n",
    "            lambda x: eval(x) if isinstance(x, str) else x\n",
    "        ).tolist()\n",
    "        label_mapping = create_label_mapping(all_narratives)\n",
    "        \n",
    "        # Prepare data\n",
    "        texts, labels, label_mapping = prepare_data(df, label_mapping)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
    "            texts, labels, test_size=0.2, random_state=42,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Vectorize text using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        X_train = vectorizer.fit_transform(X_train_texts)\n",
    "        X_test = vectorizer.transform(X_test_texts)\n",
    "        #print(y)\n",
    "        # Train SVM using OneVsRestClassifier\n",
    "        model = OneVsRestClassifier(LinearSVC())\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = model.predict(X_test)\n",
    "        #print(y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        logger.info(\"Training classification report:\")\n",
    "        logger.info(json.dumps(report, indent=2))\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in SVM training: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_svm(text, model_path, vectorizer_path):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained SVM model.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify.\n",
    "        model_path: Path to the saved SVM model.\n",
    "        vectorizer_path: Path to the saved TF-IDF vectorizer.\n",
    "    \n",
    "    Returns:\n",
    "        list: Predicted class indices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and vectorizer\n",
    "        model = joblib.load(model_path)\n",
    "        vectorizer = joblib.load(vectorizer_path)\n",
    "        \n",
    "        # Load label mapping\n",
    "        with open(os.path.join(os.path.dirname(model_path), \"label_mapping.json\"), 'r') as f:\n",
    "            label_mapping = json.load(f)\n",
    "        \n",
    "        # Convert label indices to their original labels\n",
    "        idx_to_label = {v: k for k, v in label_mapping.items()}\n",
    "        \n",
    "        # Transform input text using vectorizer\n",
    "        X = vectorizer.transform([text])\n",
    "        \n",
    "        # Predict\n",
    "        predictions = model.predict(X)[0]\n",
    "        predicted_labels = [idx_to_label[idx] for idx in range(len(predictions)) if predictions[idx] == 1]\n",
    "        print(predicted_labels)\n",
    "        return predicted_labels\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in SVM prediction: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:54,426 - __main__ - INFO - Starting SVM training with Ukraine War data...\n",
      "2024-12-14 16:02:54,428 - __main__ - INFO - Created mapping for 42 unique narratives\n",
      "2024-12-14 16:02:54,431 - __main__ - INFO - Number of unique labels in mapping: 42\n",
      "2024-12-14 16:02:54,433 - __main__ - INFO - Sample text: world need peacemaker trump jeff crouere liberty daily world total chaos month biden presidency sout\n",
      "2024-12-14 16:02:54,435 - __main__ - INFO - Sample label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2024-12-14 16:02:54,598 - __main__ - INFO - Model saved to c:\\Users\\leonb\\OneDrive\\Dokumente\\Studium\\Master\\Sem1\\NLP and InfExt\\practical\\nlp_Backpropagandists_2024\\code\\./models/svm_model.joblib\n",
      "2024-12-14 16:02:54,610 - __main__ - INFO - Training classification report:\n",
      "2024-12-14 16:02:54,610 - __main__ - INFO - {\n",
      "  \"0\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.25,\n",
      "    \"f1-score\": 0.4,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"6\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"7\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"8\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"9\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"10\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"11\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"12\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"13\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"14\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"15\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"16\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"17\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"18\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"19\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"20\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"21\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"22\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"23\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"24\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"25\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"26\": {\n",
      "    \"precision\": 0.7142857142857143,\n",
      "    \"recall\": 0.5,\n",
      "    \"f1-score\": 0.5882352941176471,\n",
      "    \"support\": 10.0\n",
      "  },\n",
      "  \"27\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"28\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"29\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"30\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"31\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"32\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"33\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"34\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"35\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"36\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"37\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"38\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"39\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"40\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"41\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"micro avg\": {\n",
      "    \"precision\": 0.7777777777777778,\n",
      "    \"recall\": 0.13725490196078433,\n",
      "    \"f1-score\": 0.23333333333333334,\n",
      "    \"support\": 51.0\n",
      "  },\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.06462585034013606,\n",
      "    \"recall\": 0.041666666666666664,\n",
      "    \"f1-score\": 0.04733893557422969,\n",
      "    \"support\": 51.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 0.23809523809523808,\n",
      "    \"recall\": 0.13725490196078433,\n",
      "    \"f1-score\": 0.166320645905421,\n",
      "    \"support\": 51.0\n",
      "  },\n",
      "  \"samples avg\": {\n",
      "    \"precision\": 0.2692307692307692,\n",
      "    \"recall\": 0.25,\n",
      "    \"f1-score\": 0.2564102564102564,\n",
      "    \"support\": 51.0\n",
      "  }\n",
      "}\n",
      "2024-12-14 16:02:54,610 - __main__ - INFO - BERT training completed. Results: {'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4.0}, '4': {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 4.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '13': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4.0}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '25': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '26': {'precision': 0.7142857142857143, 'recall': 0.5, 'f1-score': 0.5882352941176471, 'support': 10.0}, '27': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '28': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '29': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '30': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '31': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '32': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '33': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '34': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '35': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '36': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '37': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '38': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '39': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '40': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '41': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'micro avg': {'precision': 0.7777777777777778, 'recall': 0.13725490196078433, 'f1-score': 0.23333333333333334, 'support': 51.0}, 'macro avg': {'precision': 0.06462585034013606, 'recall': 0.041666666666666664, 'f1-score': 0.04733893557422969, 'support': 51.0}, 'weighted avg': {'precision': 0.23809523809523808, 'recall': 0.13725490196078433, 'f1-score': 0.166320645905421, 'support': 51.0}, 'samples avg': {'precision': 0.2692307692307692, 'recall': 0.25, 'f1-score': 0.2564102564102564, 'support': 51.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 23 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting SVM training with Ukraine War data...\")\n",
    "training_results = train_svm(df_ua, base_path)\n",
    "logger.info(f\"BERT training completed. Results: {training_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:54,628 - __main__ - INFO - Starting SVM training with Climate Change data...\n",
      "2024-12-14 16:02:54,628 - __main__ - INFO - Created mapping for 29 unique narratives\n",
      "2024-12-14 16:02:54,632 - __main__ - INFO - Number of unique labels in mapping: 29\n",
      "2024-12-14 16:02:54,633 - __main__ - INFO - Sample text: strategy need preserve water resource pakistan islamabadpakistan need chalk effective feasible plan \n",
      "2024-12-14 16:02:54,633 - __main__ - INFO - Sample label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "2024-12-14 16:02:54,700 - __main__ - INFO - Model saved to c:\\Users\\leonb\\OneDrive\\Dokumente\\Studium\\Master\\Sem1\\NLP and InfExt\\practical\\nlp_Backpropagandists_2024\\code\\./models/svm_model.joblib\n",
      "2024-12-14 16:02:54,711 - __main__ - INFO - Training classification report:\n",
      "2024-12-14 16:02:54,712 - __main__ - INFO - {\n",
      "  \"0\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"6\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"7\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"8\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"9\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"10\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"11\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"12\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"13\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"14\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"15\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"16\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"17\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"18\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"19\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"20\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"21\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"22\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"23\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"24\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.8,\n",
      "    \"f1-score\": 0.8888888888888888,\n",
      "    \"support\": 15.0\n",
      "  },\n",
      "  \"25\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"26\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"27\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"28\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"micro avg\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.8,\n",
      "    \"f1-score\": 0.8888888888888888,\n",
      "    \"support\": 15.0\n",
      "  },\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.034482758620689655,\n",
      "    \"recall\": 0.027586206896551727,\n",
      "    \"f1-score\": 0.03065134099616858,\n",
      "    \"support\": 15.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.8,\n",
      "    \"f1-score\": 0.8888888888888888,\n",
      "    \"support\": 15.0\n",
      "  },\n",
      "  \"samples avg\": {\n",
      "    \"precision\": 0.8,\n",
      "    \"recall\": 0.8,\n",
      "    \"f1-score\": 0.8,\n",
      "    \"support\": 15.0\n",
      "  }\n",
      "}\n",
      "2024-12-14 16:02:54,714 - __main__ - INFO - SVM training completed. Results: {'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '13': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '24': {'precision': 1.0, 'recall': 0.8, 'f1-score': 0.8888888888888888, 'support': 15.0}, '25': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '26': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '27': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '28': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'micro avg': {'precision': 1.0, 'recall': 0.8, 'f1-score': 0.8888888888888888, 'support': 15.0}, 'macro avg': {'precision': 0.034482758620689655, 'recall': 0.027586206896551727, 'f1-score': 0.03065134099616858, 'support': 15.0}, 'weighted avg': {'precision': 1.0, 'recall': 0.8, 'f1-score': 0.8888888888888888, 'support': 15.0}, 'samples avg': {'precision': 0.8, 'recall': 0.8, 'f1-score': 0.8, 'support': 15.0}}\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting SVM training with Climate Change data...\")\n",
    "training_results = train_svm(df_cc, base_path)\n",
    "logger.info(f\"SVM training completed. Results: {training_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:02:54,726 - __main__ - INFO - Starting SVM training with the complete data...\n",
      "2024-12-14 16:02:54,729 - __main__ - INFO - Created mapping for 69 unique narratives\n",
      "2024-12-14 16:02:54,734 - __main__ - INFO - Number of unique labels in mapping: 69\n",
      "2024-12-14 16:02:54,734 - __main__ - INFO - Sample text: world need peacemaker trump jeff crouere liberty daily world total chaos month biden presidency sout\n",
      "2024-12-14 16:02:54,736 - __main__ - INFO - Sample label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2024-12-14 16:02:54,915 - __main__ - INFO - Model saved to c:\\Users\\leonb\\OneDrive\\Dokumente\\Studium\\Master\\Sem1\\NLP and InfExt\\practical\\nlp_Backpropagandists_2024\\code\\./models/svm_model.joblib\n",
      "2024-12-14 16:02:54,934 - __main__ - INFO - Training classification report:\n",
      "2024-12-14 16:02:54,936 - __main__ - INFO - {\n",
      "  \"0\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"6\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"7\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"8\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"9\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"10\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"11\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"12\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"13\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"14\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"15\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"16\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"17\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"18\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"19\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"20\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"21\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"22\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"23\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"24\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"25\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"26\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 3.0\n",
      "  },\n",
      "  \"27\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"28\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"29\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"30\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"31\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"32\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1-score\": 1.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"33\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"34\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"35\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"36\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"37\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"38\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"39\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"40\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"41\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"42\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"43\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"44\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"45\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"46\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"47\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"48\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"49\": {\n",
      "    \"precision\": 0.75,\n",
      "    \"recall\": 0.45,\n",
      "    \"f1-score\": 0.5625,\n",
      "    \"support\": 20.0\n",
      "  },\n",
      "  \"50\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"51\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"52\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"53\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"54\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"55\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"56\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"57\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"58\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"59\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"60\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"61\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"62\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"63\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"64\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 1.0\n",
      "  },\n",
      "  \"65\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"66\": {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.5,\n",
      "    \"f1-score\": 0.6666666666666666,\n",
      "    \"support\": 2.0\n",
      "  },\n",
      "  \"67\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 0.0\n",
      "  },\n",
      "  \"68\": {\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0,\n",
      "    \"f1-score\": 0.0,\n",
      "    \"support\": 4.0\n",
      "  },\n",
      "  \"micro avg\": {\n",
      "    \"precision\": 0.631578947368421,\n",
      "    \"recall\": 0.14814814814814814,\n",
      "    \"f1-score\": 0.24,\n",
      "    \"support\": 81.0\n",
      "  },\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.05434782608695652,\n",
      "    \"recall\": 0.0427536231884058,\n",
      "    \"f1-score\": 0.04679951690821256,\n",
      "    \"support\": 81.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 0.2345679012345679,\n",
      "    \"recall\": 0.14814814814814814,\n",
      "    \"f1-score\": 0.1800411522633745,\n",
      "    \"support\": 81.0\n",
      "  },\n",
      "  \"samples avg\": {\n",
      "    \"precision\": 0.2625,\n",
      "    \"recall\": 0.275,\n",
      "    \"f1-score\": 0.26666666666666666,\n",
      "    \"support\": 81.0\n",
      "  }\n",
      "}\n",
      "2024-12-14 16:02:54,938 - __main__ - INFO - SVM training completed. Results: {'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '13': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '25': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '26': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '27': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '28': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '29': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '30': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '31': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '32': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '33': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '34': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '35': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '36': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '37': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '38': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '39': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '40': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '41': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '42': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '43': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '44': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '45': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '46': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '47': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '48': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '49': {'precision': 0.75, 'recall': 0.45, 'f1-score': 0.5625, 'support': 20.0}, '50': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '51': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '52': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '53': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '54': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '55': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '56': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '57': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '58': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '59': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2.0}, '60': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '61': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '62': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '63': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '64': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '65': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '66': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 2.0}, '67': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '68': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4.0}, 'micro avg': {'precision': 0.631578947368421, 'recall': 0.14814814814814814, 'f1-score': 0.24, 'support': 81.0}, 'macro avg': {'precision': 0.05434782608695652, 'recall': 0.0427536231884058, 'f1-score': 0.04679951690821256, 'support': 81.0}, 'weighted avg': {'precision': 0.2345679012345679, 'recall': 0.14814814814814814, 'f1-score': 0.1800411522633745, 'support': 81.0}, 'samples avg': {'precision': 0.2625, 'recall': 0.275, 'f1-score': 0.26666666666666666, 'support': 81.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 40 is present in all training examples.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 41 is present in all training examples.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 52 is present in all training examples.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 58 is present in all training examples.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonb\\anaconda3\\envs\\NLP_BP\\lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 60 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting SVM training with the complete data...\")\n",
    "training_results = train_svm(df, base_path)\n",
    "logger.info(f\"SVM training completed. Results: {training_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis\n",
    "\n",
    "### Performance\n",
    "**Precision and recall consideration**\n",
    "\n",
    "- To evaluate performance, we look at the recall, precision and f1-score\n",
    "- Generally, the SVM yields a higher precision than recall, indicating that the model is more accurate when predicting a narrative for an article, but it \"misses\" more narratives that actually apply to an article. We argue that a high recall is more relevant for this task.\n",
    "- Given the example of assigning articles on X (formerly twitter)  to certain narratives to flag to it like \"A problematic narrative x might be contained in this article\", we are more interested in actually finding all relevant narratives.\n",
    "- Therefore, if we optimise our results, we will do it with respect to recall\n",
    "\n",
    "- possibly differentiate between classes (what to do depending how high prec/recall)\n",
    "\n",
    "**Model performance**\n",
    "\n",
    "- After considering precision vs. recall, we will focus on f1 score, which is a combination of the two, in the following as a single value for comparison.\n",
    "- Generally, the resulting f1-score on the test set is quite low. If we look at the weighted average, it becomes slightly better since underrepresented classes, for which the model has almost no chance of learning them, are not weighted equally. This is due to multiple reasons:\n",
    "    - task complexity with a large output space in terms of class number and multiple labels that can apply to an article\n",
    "    - additionally, the class distribution is highly unbalanced\n",
    "    - Lastly, with only using the english data, we have a quite limited dataset size, especially when considering the task complexity\n",
    "    - lastly, the method of one-vs-rest classification with SVMs likely lacks the suitable capacity for this task\n",
    "\n",
    "- When comparing training the classifier using the whole data as opposed to just the climate change data or the ukraine war data, we observe that the weighted average f1 score \n",
    "\n",
    "### Task specific problems\n",
    "- Get the problem-instances\n",
    "\n",
    "**Class representation**\n",
    "\n",
    "When training the SVM, a user warning occurs: \"Label not :NUMBER: is present in all training examples\". This is sklearns weird way of saying that there are label indices that do not occur in any of the training data instances. This happens the following way:\n",
    "- The unique labels are generated using the whole dataset\n",
    "- After making the train-test-split, it is likely that classes that have a low representation did not make it into the training set\n",
    "\n",
    "The result of this is that the model obviously can't learn how to predict this class, resulting in no correct predictions for it. This is a problem specific problem, since in multi-class classification (xx classes), it frequently occurs that some classes are represented a lot and others very rarely.\n",
    "\n",
    "Upon further analysis, we observe that there are classes that have very few occurances (even single occurances). This is a problem since it makes dealing with this problem challenging.\n",
    "- Stratification at the train-test-split level could resolve this problem by ensuring the distribution of the classes is the same in train and test\n",
    "    - With single occurances of classes, this is not possible since at least two occurances per class are necessary\n",
    "- Using SMOTE to create synthetic training instances for underrepresented classes\n",
    "    - For this as well, more than one occurance per class is necessary since the synthetic examples are generated using the \"nearest neighbors\" of that class\n",
    "- Another way of dealing with the problem is to copy instances of classes that only occur once and then using stratification. Since that would lead to leakage from the training into the test data, this is worse than not addressing it since that way, the performance would be artificially raised.\n",
    "\n",
    "Addressing this problem further will be a task for the final project submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
