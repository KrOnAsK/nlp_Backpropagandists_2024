{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Llama model's performance across the different datasets reveals interesting patterns in how it handles narrative classification tasks. When trained on the Climate Change (CC) dataset alone, the model achieved its strongest results with a final accuracy of 0.625 and an F1 score of 0.665. This suggests that the model was able to effectively learn and distinguish between different climate change-related narratives.\n",
    "\n",
    "However, when trained on the full combined dataset, which included both climate change and Ukraine-related narratives, the model's performance decreased notably, achieving an accuracy of 0.316 and an F1 score of 0.431. This decline in performance tells us something important about how Llama handles increasing narrative complexity. The lower metrics on the combined dataset likely indicate that the model struggled to maintain clear boundaries between similar narrative types when dealing with a broader context spanning multiple domains.\n",
    "\n",
    "The difference in performance between the focused CC dataset and the combined dataset highlights a fundamental challenge in narrative classification: as the number and variety of possible narratives increase, the task of distinguishing between them becomes exponentially more complex. This is particularly relevant when narratives from different domains might share similar linguistic patterns or rhetorical structures, making it harder for the model to make clean distinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import torch\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from huggingface_hub import login\n",
    "\n",
    "from model import initialize_model, setup_peft\n",
    "from data_utils import prepare_data, get_predictions_batch, prepare_data_for_model, ensure_model_on_device\n",
    "from trainer import train_model\n",
    "from debug_utils import debug_misclassifications\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_dataset(df, model_name, output_dir, current_date, dataset_name):\n",
    "    \"\"\"\n",
    "    Train model on a single dataset\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the dataset\n",
    "        model_name: Name of the model to use\n",
    "        output_dir: Directory to save outputs\n",
    "        current_date: Current date string for naming\n",
    "        dataset_name: Name of the dataset for logging\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (results, model, tokenizer, label_mapping, df)  # Added df to return values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create dataset-specific output directory\n",
    "        dataset_output_dir = os.path.join(output_dir, f\"{dataset_name}_{current_date}\")\n",
    "        os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nTraining on {dataset_name} dataset...\")\n",
    "        \n",
    "        # Initialize wandb run for this dataset\n",
    "        wandb.init(\n",
    "            project=\"llama-classification\",\n",
    "            name=f\"llama-classification-{dataset_name}-{current_date}\",\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # Prepare data\n",
    "        train_dataset, val_dataset, tokenizer, label_mapping, num_labels = prepare_data(\n",
    "            df, \n",
    "            model_name, \n",
    "            dataset_output_dir\n",
    "        )\n",
    "        \n",
    "        # Initialize and setup model\n",
    "        print(\"\\nInitializing model...\")\n",
    "        model = initialize_model(model_name, num_labels)\n",
    "        model = setup_peft(model)\n",
    "        \n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create data collator that handles device placement\n",
    "        from transformers import DataCollatorWithPadding\n",
    "        \n",
    "        data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=tokenizer,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        def collate_fn(batch):\n",
    "            # Collate the batch using the data collator\n",
    "            batch = data_collator(batch)\n",
    "            # Move to device\n",
    "            return {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                   for k, v in batch.items()}\n",
    "        \n",
    "        # Train model with custom collate_fn\n",
    "        trainer = train_model(\n",
    "            model, \n",
    "            train_dataset, \n",
    "            val_dataset, \n",
    "            dataset_output_dir, \n",
    "            current_date, \n",
    "            dataset_name,\n",
    "            collate_fn=collate_fn  # Pass the custom collate function\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"\\nEvaluating model...\")\n",
    "        results = trainer.evaluate()\n",
    "        \n",
    "        print(f\"\\nEvaluation results for {dataset_name} dataset:\")\n",
    "        for metric, value in results.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{metric}: {value}\")\n",
    "        \n",
    "        # Save model and tokenizer\n",
    "        print(f\"\\nSaving {dataset_name} model...\")\n",
    "        trainer.save_model(dataset_output_dir)\n",
    "        tokenizer.save_pretrained(dataset_output_dir)\n",
    "        \n",
    "        # End wandb run\n",
    "        wandb.finish()\n",
    "        \n",
    "        # Return df along with other outputs\n",
    "        return results, model, tokenizer, label_mapping, df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training {dataset_name} dataset: {str(e)}\")\n",
    "        wandb.finish()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training():\n",
    "    try:\n",
    "        # Login to Hugging Face\n",
    "        login('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')\n",
    "\n",
    "        # Check CUDA availability\n",
    "        print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "        # Set paths\n",
    "        def find_repo_root():\n",
    "            current = os.getcwd()\n",
    "            while current != os.path.dirname(current):\n",
    "                if os.path.exists(os.path.join(current, '.git')):\n",
    "                    return current\n",
    "                current = os.path.dirname(current)\n",
    "            raise Exception(\"No .git directory found - repository root could not be determined\")\n",
    "\n",
    "        # Set paths using repository root\n",
    "        repo_root = find_repo_root()\n",
    "        code_path = os.path.join(repo_root, \"code\")\n",
    "        current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "        output_dir = os.path.join(code_path, \"models\", f\"llama_{current_date}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Load data from code directory\n",
    "        print(\"\\nLoading datasets...\")\n",
    "        print(f\"Repository root: {repo_root}\")\n",
    "        print(f\"Looking for data files in: {code_path}\")\n",
    "        input_file_full = os.path.join(code_path, \"df_normalized.csv\")\n",
    "        input_file_ua = os.path.join(code_path, \"df_normalized_ua.csv\")\n",
    "        input_file_cc = os.path.join(code_path, \"df_normalized_cc.csv\")\n",
    "\n",
    "        df_normalized = pd.read_csv(input_file_full)\n",
    "        df_normalized_ua = pd.read_csv(input_file_ua)\n",
    "        df_normalized_cc = pd.read_csv(input_file_cc)\n",
    "\n",
    "        # Model configuration\n",
    "        model_name = \"openlm-research/open_llama_3b\"\n",
    "        \n",
    "        return {\n",
    "            'output_dir': output_dir,\n",
    "            'current_date': current_date,\n",
    "            'model_name': model_name,\n",
    "            'df_normalized': df_normalized,\n",
    "            'df_normalized_ua': df_normalized_ua,\n",
    "            'df_normalized_cc': df_normalized_cc\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in setup: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        wandb.finish()\n",
    "        raise\n",
    "\n",
    "def train_ua():\n",
    "    try:\n",
    "        # Get setup configuration\n",
    "        config = setup_training()\n",
    "        \n",
    "        print(\"\\nStarting UA dataset training...\")\n",
    "        ua_results, ua_model, ua_tokenizer, ua_label_mapping, df_normalized_ua = train_single_dataset(\n",
    "        config['df_normalized_ua'], \n",
    "        config['model_name'], \n",
    "        config['output_dir'], \n",
    "        config['current_date'], \n",
    "        \"ua\"    \n",
    "        )\n",
    "        \n",
    "        return ua_results, ua_model, ua_tokenizer, ua_label_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in UA training: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        wandb.finish()\n",
    "        raise\n",
    "\n",
    "def train_cc():\n",
    "    try:\n",
    "        # Get setup configuration\n",
    "        config = setup_training()\n",
    "        \n",
    "        print(\"\\nStarting CC dataset training...\")\n",
    "        cc_results, cc_model, cc_tokenizer, cc_label_mapping, df_normalized_cc = train_single_dataset(\n",
    "            config['df_normalized_cc'], \n",
    "            config['model_name'], \n",
    "            config['output_dir'], \n",
    "            config['current_date'], \n",
    "            \"cc\"\n",
    "        )\n",
    "        \n",
    "        return cc_results, cc_model, cc_tokenizer, cc_label_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in CC training: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        wandb.finish()\n",
    "        raise\n",
    "\n",
    "def train_full():\n",
    "    try:\n",
    "        # Get setup configuration\n",
    "        config = setup_training()\n",
    "        \n",
    "        print(\"\\nStarting full dataset training...\")\n",
    "        results, model, tokenizer, label_mapping, df_normalized = train_single_dataset(\n",
    "            config['df_normalized'], \n",
    "            config['model_name'], \n",
    "            config['output_dir'], \n",
    "            config['current_date'], \n",
    "            \"full\"\n",
    "        )\n",
    "        \n",
    "        return results, model, tokenizer, label_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in full dataset training: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        wandb.finish()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_model(model, dataset, tokenizer, label_mapping, dataset_type=\"Training\"):\n",
    "    \"\"\"Run debug analysis on model predictions\"\"\"\n",
    "    try:\n",
    "        # Set up model and device\n",
    "        model, device = ensure_model_on_device(model)\n",
    "        print(f\"\\nAnalyzing {dataset_type} dataset...\")\n",
    "        \n",
    "        # Prepare texts\n",
    "        texts = dataset['tokens_normalized'].apply(\n",
    "            lambda x: ' '.join(x) if isinstance(x, list) else x\n",
    "        ).tolist()\n",
    "        \n",
    "        true_labels = torch.tensor([\n",
    "            label_mapping[get_narrative_key(eval(n)[0] if isinstance(n, str) else n[0])]\n",
    "            for n in dataset['narrative_subnarrative_pairs']\n",
    "        ]).to(device)\n",
    "        \n",
    "        print(f\"Total samples: {len(texts)}\")\n",
    "        \n",
    "        # Get predictions in batches\n",
    "        batch_size = 8\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            batch_preds, batch_confs = get_predictions_batch(model, batch_texts, tokenizer, device)\n",
    "            predictions.append(batch_preds)\n",
    "            confidences.append(batch_confs)\n",
    "        \n",
    "        # Concatenate and move to CPU\n",
    "        predictions = torch.cat(predictions).cpu().numpy()\n",
    "        confidences = torch.cat(confidences).cpu().numpy()\n",
    "        true_labels = true_labels.cpu().numpy()\n",
    "        \n",
    "        # Track misclassifications\n",
    "        misclassifications = []\n",
    "        for idx, (pred, true, conf) in enumerate(zip(predictions, true_labels, confidences)):\n",
    "            if pred != true:\n",
    "                misclassifications.append({\n",
    "                    'text': texts[idx][:200],\n",
    "                    'predicted': pred,\n",
    "                    'actual': true,\n",
    "                    'confidence': conf,\n",
    "                    'dataset_type': dataset_type\n",
    "                })\n",
    "        \n",
    "        # Create DataFrame and display results\n",
    "        misclass_df = pd.DataFrame(misclassifications)\n",
    "        print(f\"\\nTotal misclassifications: {len(misclass_df)}\")\n",
    "        print(f\"Accuracy: {1 - len(misclass_df)/len(texts):.4f}\")\n",
    "        \n",
    "        if len(misclass_df) > 0:\n",
    "            print(\"\\nMisclassification distribution:\")\n",
    "            print(misclass_df.groupby(['actual', 'predicted']).size().unstack(fill_value=0))\n",
    "            \n",
    "            print(\"\\nSample misclassifications:\")\n",
    "            for i, row in misclass_df.head().iterrows():\n",
    "                print(f\"\\nExample {i+1}:\")\n",
    "                print(f\"Text: {row['text']}\")\n",
    "                print(f\"Predicted: {row['predicted']}, Actual: {row['actual']}\")\n",
    "                print(f\"Confidence: {row['confidence']:.4f}\")\n",
    "        \n",
    "        return misclass_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in debug analysis: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU Memory: 11.81 GB\n",
      "\n",
      "Loading datasets...\n",
      "Repository root: c:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\n",
      "Looking for data files in: c:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\\code\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = setup_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device: NVIDIA GeForce RTX 2080 Ti\n",
      "GPU Memory: 11.81 GB\n",
      "\n",
      "Loading datasets...\n",
      "Repository root: c:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\n",
      "Looking for data files in: c:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\\code\n",
      "\n",
      "Starting UA dataset training...\n",
      "\n",
      "Training on ua dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonaskruse\u001b[0m (\u001b[33mbackpropagandists\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\\code\\dl_methods\\llama\\wandb\\run-20250124_221306-m23azklg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/backpropagandists/llama-classification/runs/m23azklg' target=\"_blank\">llama-classification-ua-20250124</a></strong> to <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/backpropagandists/llama-classification/runs/m23azklg' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification/runs/m23azklg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating narrative mapping...\n",
      "Number of unique narratives: 12\n",
      "\n",
      "Sample narrative mappings:\n",
      "0: Amplifying war-related fears\n",
      "1: Blaming the war on others rather than the invader\n",
      "2: Discrediting Ukraine\n",
      "3: Discrediting the West, Diplomacy\n",
      "4: Distrust towards Media\n",
      "\n",
      "Training set size: 940\n",
      "Validation set size: 235\n",
      "\n",
      "Initializing tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing texts...\n",
      "\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 22:13:14,924 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at openlm-research/open_llama_3b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,688,000 || all params: 3,334,800,000 || trainable%: 0.3205\n",
      "\n",
      "Starting classification head pre-training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 22:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.132800</td>\n",
       "      <td>2.164670</td>\n",
       "      <td>0.242553</td>\n",
       "      <td>0.141290</td>\n",
       "      <td>0.115708</td>\n",
       "      <td>0.242553</td>\n",
       "      <td>{'Class_0': [[216, 0], [19, 0]], 'Class_1': [[219, 0], [16, 0]], 'Class_2': [[54, 140], [4, 37]], 'Class_3': [[206, 0], [29, 0]], 'Class_4': [[233, 0], [2, 0]], 'Class_5': [[233, 0], [2, 0]], 'Class_6': [[226, 0], [9, 0]], 'Class_7': [[143, 38], [34, 20]], 'Class_8': [[233, 0], [2, 0]], 'Class_9': [[199, 0], [36, 0]], 'Class_10': [[221, 0], [14, 0]], 'Class_11': [[224, 0], [11, 0]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[216   0]\n",
      " [ 19   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[219   0]\n",
      " [ 16   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[ 54 140]\n",
      " [  4  37]]\n",
      "Precision: 0.2090\n",
      "Recall: 0.9024\n",
      "F1 Score: 0.3394\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[206   0]\n",
      " [ 29   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[226   0]\n",
      " [  9   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[143  38]\n",
      " [ 34  20]]\n",
      "Precision: 0.3448\n",
      "Recall: 0.3704\n",
      "F1 Score: 0.3571\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[199   0]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[221   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[224   0]\n",
      " [ 11   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting full model fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [351/351 1:00:23, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.144000</td>\n",
       "      <td>2.120298</td>\n",
       "      <td>0.246809</td>\n",
       "      <td>0.145393</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>0.246809</td>\n",
       "      <td>{'Class_0': [[216, 0], [19, 0]], 'Class_1': [[219, 0], [16, 0]], 'Class_2': [[54, 140], [4, 37]], 'Class_3': [[206, 0], [29, 0]], 'Class_4': [[233, 0], [2, 0]], 'Class_5': [[233, 0], [2, 0]], 'Class_6': [[226, 0], [9, 0]], 'Class_7': [[144, 37], [33, 21]], 'Class_8': [[233, 0], [2, 0]], 'Class_9': [[199, 0], [36, 0]], 'Class_10': [[221, 0], [14, 0]], 'Class_11': [[224, 0], [11, 0]]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.179900</td>\n",
       "      <td>2.122152</td>\n",
       "      <td>0.246809</td>\n",
       "      <td>0.145393</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>0.246809</td>\n",
       "      <td>{'Class_0': [[216, 0], [19, 0]], 'Class_1': [[219, 0], [16, 0]], 'Class_2': [[54, 140], [4, 37]], 'Class_3': [[206, 0], [29, 0]], 'Class_4': [[233, 0], [2, 0]], 'Class_5': [[233, 0], [2, 0]], 'Class_6': [[226, 0], [9, 0]], 'Class_7': [[144, 37], [33, 21]], 'Class_8': [[233, 0], [2, 0]], 'Class_9': [[199, 0], [36, 0]], 'Class_10': [[221, 0], [14, 0]], 'Class_11': [[224, 0], [11, 0]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[216   0]\n",
      " [ 19   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[219   0]\n",
      " [ 16   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[ 54 140]\n",
      " [  4  37]]\n",
      "Precision: 0.2090\n",
      "Recall: 0.9024\n",
      "F1 Score: 0.3394\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[206   0]\n",
      " [ 29   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[226   0]\n",
      " [  9   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[144  37]\n",
      " [ 33  21]]\n",
      "Precision: 0.3621\n",
      "Recall: 0.3889\n",
      "F1 Score: 0.3750\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[199   0]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[221   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[224   0]\n",
      " [ 11   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[216   0]\n",
      " [ 19   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[219   0]\n",
      " [ 16   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[ 54 140]\n",
      " [  4  37]]\n",
      "Precision: 0.2090\n",
      "Recall: 0.9024\n",
      "F1 Score: 0.3394\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[206   0]\n",
      " [ 29   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[226   0]\n",
      " [  9   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[144  37]\n",
      " [ 33  21]]\n",
      "Precision: 0.3621\n",
      "Recall: 0.3889\n",
      "F1 Score: 0.3750\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[199   0]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[221   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[224   0]\n",
      " [ 11   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[216   0]\n",
      " [ 19   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[219   0]\n",
      " [ 16   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[ 54 140]\n",
      " [  4  37]]\n",
      "Precision: 0.2090\n",
      "Recall: 0.9024\n",
      "F1 Score: 0.3394\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[206   0]\n",
      " [ 29   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[226   0]\n",
      " [  9   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[144  37]\n",
      " [ 33  21]]\n",
      "Precision: 0.3621\n",
      "Recall: 0.3889\n",
      "F1 Score: 0.3750\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[199   0]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[221   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[224   0]\n",
      " [ 11   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[216   0]\n",
      " [ 19   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[219   0]\n",
      " [ 16   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[ 54 140]\n",
      " [  4  37]]\n",
      "Precision: 0.2090\n",
      "Recall: 0.9024\n",
      "F1 Score: 0.3394\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[206   0]\n",
      " [ 29   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[226   0]\n",
      " [  9   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[144  37]\n",
      " [ 33  21]]\n",
      "Precision: 0.3621\n",
      "Recall: 0.3889\n",
      "F1 Score: 0.3750\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[233   0]\n",
      " [  2   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[199   0]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[221   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[224   0]\n",
      " [ 11   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Evaluation results for ua dataset:\n",
      "eval_loss: 2.1134\n",
      "eval_accuracy: 0.2468\n",
      "eval_f1: 0.1454\n",
      "eval_precision: 0.1197\n",
      "eval_recall: 0.2468\n",
      "eval_confusion_matrix: {'Class_0': [[216, 0], [19, 0]], 'Class_1': [[219, 0], [16, 0]], 'Class_2': [[54, 140], [4, 37]], 'Class_3': [[206, 0], [29, 0]], 'Class_4': [[233, 0], [2, 0]], 'Class_5': [[233, 0], [2, 0]], 'Class_6': [[226, 0], [9, 0]], 'Class_7': [[144, 37], [33, 21]], 'Class_8': [[233, 0], [2, 0]], 'Class_9': [[199, 0], [36, 0]], 'Class_10': [[221, 0], [14, 0]], 'Class_11': [[224, 0], [11, 0]]}\n",
      "eval_runtime: 84.7494\n",
      "eval_samples_per_second: 2.7730\n",
      "eval_steps_per_second: 0.6960\n",
      "epoch: 2.9787\n",
      "\n",
      "Saving ua model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications in Training dataset...\n",
      "Model is on device: cuda:0\n",
      "\n",
      "Total samples to analyze: 1175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train UA dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ua_results, ua_model, ua_tokenizer, ua_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ua\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m, in \u001b[0;36mtrain_ua\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     config \u001b[38;5;241m=\u001b[39m setup_training()\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting UA dataset training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     ua_results, ua_model, ua_tokenizer, ua_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_normalized_ua\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mua\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ua_results, ua_model, ua_tokenizer, ua_label_mapping\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m, in \u001b[0;36mtrain_single_dataset\u001b[1;34m(df, model_name, output_dir, current_date, dataset_name)\u001b[0m\n\u001b[0;32m     87\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(dataset_output_dir)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Debug misclassifications\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m misclass_df \u001b[38;5;241m=\u001b[39m \u001b[43mdebug_misclassifications\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# End wandb run\u001b[39;00m\n\u001b[0;32m     93\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[1;32mc:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\\code\\dl_methods\\llama\\debug_utils.py:45\u001b[0m, in \u001b[0;36mdebug_misclassifications\u001b[1;34m(dataset, model, tokenizer, label_mapping, dataset_type)\u001b[0m\n\u001b[0;32m     42\u001b[0m # Explicitly move each tensor to the device\n\u001b[0;32m     43\u001b[0m encodings = {k: v.to(device) for k, v in encodings.items()}\n\u001b[1;32m---> 45\u001b[0m # Forward pass\n\u001b[0;32m     46\u001b[0m with torch.no_grad():\n\u001b[0;32m     47\u001b[0m     outputs = model(**encodings)  # Use unpacking to handle all inputs\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\peft\\peft_model.py:1521\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[0;32m   1520\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[1;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[0;32m   1522\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1523\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1524\u001b[0m             inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1525\u001b[0m             labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   1526\u001b[0m             output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1527\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1528\u001b[0m             return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1529\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1530\u001b[0m         )\n\u001b[0;32m   1532\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:919\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    917\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 919\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    931\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:589\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    578\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    579\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    586\u001b[0m         position_embeddings,\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    590\u001b[0m         hidden_states,\n\u001b[0;32m    591\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    592\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    593\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    594\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    595\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    596\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    597\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[0;32m    599\u001b[0m     )\n\u001b[0;32m    601\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krona\\.conda\\envs\\llama\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:349\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m    348\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m--> 349\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mresidual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\n\u001b[0;32m    351\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train UA dataset\n",
    "ua_results, ua_model, ua_tokenizer, ua_label_mapping, df_normalized_ua = train_ua()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_debug_df = debug_model(ua_model, df_normalized_ua, ua_tokenizer, ua_label_mapping, \"UA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device: NVIDIA L40S\n",
      "GPU Memory: 47.81 GB\n",
      "\n",
      "Loading datasets...\n",
      "Repository root: /teamspace/studios/this_studio/nlp_Backpropagandists_2024\n",
      "Looking for data files in: /teamspace/studios/this_studio/nlp_Backpropagandists_2024/code\n",
      "\n",
      "Starting CC dataset training...\n",
      "\n",
      "Training on cc dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/nlp_Backpropagandists_2024/code/dl_methods/llama/wandb/run-20250121_133349-9904jlz8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/backpropagandists/llama-classification/runs/9904jlz8' target=\"_blank\">llama-classification-cc-20250121</a></strong> to <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/backpropagandists/llama-classification/runs/9904jlz8' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification/runs/9904jlz8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating narrative mapping...\n",
      "Number of unique narratives: 11\n",
      "\n",
      "Sample narrative mappings:\n",
      "0: Amplifying Climate Fears\n",
      "1: Climate change is beneficial\n",
      "2: Controversy about green technologies\n",
      "3: Criticism of climate movement\n",
      "4: Criticism of climate policies\n",
      "\n",
      "Training set size: 415\n",
      "Validation set size: 104\n",
      "\n",
      "Initializing tokenizer...\n",
      "\n",
      "Tokenizing texts...\n",
      "\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 13:33:51,645 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8b1dbd35324cd8a679a976a7c58b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at openlm-research/open_llama_7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,822,272 || all params: 6,624,210,944 || trainable%: 0.2540\n",
      "\n",
      "Starting classification head pre-training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 05:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.628900</td>\n",
       "      <td>1.775053</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.526456</td>\n",
       "      <td>0.488726</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>{'Class_0': [[40, 24], [3, 37]], 'Class_1': [[103, 0], [1, 0]], 'Class_3': [[94, 2], [6, 2]], 'Class_4': [[98, 2], [4, 0]], 'Class_5': [[82, 10], [10, 2]], 'Class_6': [[95, 2], [7, 0]], 'Class_7': [[103, 0], [1, 0]], 'Class_8': [[96, 0], [8, 0]], 'Class_9': [[69, 13], [12, 10]], 'Class_10': [[103, 0], [1, 0]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[40 24]\n",
      " [ 3 37]]\n",
      "Precision: 0.6066\n",
      "Recall: 0.9250\n",
      "F1 Score: 0.7327\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[94  2]\n",
      " [ 6  2]]\n",
      "Precision: 0.5000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[98  2]\n",
      " [ 4  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[82 10]\n",
      " [10  2]]\n",
      "Precision: 0.1667\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[95  2]\n",
      " [ 7  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[96  0]\n",
      " [ 8  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[69 13]\n",
      " [12 10]]\n",
      "Precision: 0.4348\n",
      "Recall: 0.4545\n",
      "F1 Score: 0.4444\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfreezing LoRA adapters for full training...\n",
      "\n",
      "Starting full model fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 16:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.853600</td>\n",
       "      <td>1.626752</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.562827</td>\n",
       "      <td>0.544105</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>{'Class_0': [[40, 24], [1, 39]], 'Class_1': [[103, 0], [1, 0]], 'Class_3': [[95, 1], [7, 1]], 'Class_4': [[99, 1], [4, 0]], 'Class_5': [[90, 2], [9, 3]], 'Class_6': [[96, 1], [7, 0]], 'Class_7': [[103, 0], [1, 0]], 'Class_8': [[96, 0], [8, 0]], 'Class_9': [[64, 18], [8, 14]], 'Class_10': [[103, 0], [1, 0]]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.177100</td>\n",
       "      <td>1.612782</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.593278</td>\n",
       "      <td>0.522068</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>{'Class_0': [[50, 14], [5, 35]], 'Class_1': [[103, 0], [1, 0]], 'Class_3': [[94, 2], [5, 3]], 'Class_4': [[93, 7], [2, 2]], 'Class_5': [[85, 7], [9, 3]], 'Class_6': [[95, 2], [7, 0]], 'Class_7': [[103, 0], [1, 0]], 'Class_8': [[93, 3], [7, 1]], 'Class_9': [[72, 10], [9, 13]], 'Class_10': [[102, 1], [1, 0]]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>1.666802</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.664835</td>\n",
       "      <td>0.632051</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>{'Class_0': [[51, 13], [3, 37]], 'Class_1': [[103, 0], [1, 0]], 'Class_3': [[93, 3], [3, 5]], 'Class_4': [[98, 2], [3, 1]], 'Class_5': [[83, 9], [6, 6]], 'Class_6': [[95, 2], [7, 0]], 'Class_7': [[103, 0], [1, 0]], 'Class_8': [[96, 0], [7, 1]], 'Class_9': [[75, 7], [7, 15]], 'Class_10': [[102, 1], [1, 0]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[40 24]\n",
      " [ 1 39]]\n",
      "Precision: 0.6190\n",
      "Recall: 0.9750\n",
      "F1 Score: 0.7573\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[95  1]\n",
      " [ 7  1]]\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[99  1]\n",
      " [ 4  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[90  2]\n",
      " [ 9  3]]\n",
      "Precision: 0.6000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3529\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[96  1]\n",
      " [ 7  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[96  0]\n",
      " [ 8  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[64 18]\n",
      " [ 8 14]]\n",
      "Precision: 0.4375\n",
      "Recall: 0.6364\n",
      "F1 Score: 0.5185\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[50 14]\n",
      " [ 5 35]]\n",
      "Precision: 0.7143\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.7865\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[94  2]\n",
      " [ 5  3]]\n",
      "Precision: 0.6000\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.4615\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[93  7]\n",
      " [ 2  2]]\n",
      "Precision: 0.2222\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[85  7]\n",
      " [ 9  3]]\n",
      "Precision: 0.3000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2727\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[95  2]\n",
      " [ 7  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[93  3]\n",
      " [ 7  1]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[72 10]\n",
      " [ 9 13]]\n",
      "Precision: 0.5652\n",
      "Recall: 0.5909\n",
      "F1 Score: 0.5778\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[102   1]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[51 13]\n",
      " [ 3 37]]\n",
      "Precision: 0.7400\n",
      "Recall: 0.9250\n",
      "F1 Score: 0.8222\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[93  3]\n",
      " [ 3  5]]\n",
      "Precision: 0.6250\n",
      "Recall: 0.6250\n",
      "F1 Score: 0.6250\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[98  2]\n",
      " [ 3  1]]\n",
      "Precision: 0.3333\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2857\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[83  9]\n",
      " [ 6  6]]\n",
      "Precision: 0.4000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.4444\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[95  2]\n",
      " [ 7  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[96  0]\n",
      " [ 7  1]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2222\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[75  7]\n",
      " [ 7 15]]\n",
      "Precision: 0.6818\n",
      "Recall: 0.6818\n",
      "F1 Score: 0.6818\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[102   1]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[50 14]\n",
      " [ 5 35]]\n",
      "Precision: 0.7143\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.7865\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 3:\n",
      "Confusion Matrix:\n",
      "[[94  2]\n",
      " [ 5  3]]\n",
      "Precision: 0.6000\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.4615\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[93  7]\n",
      " [ 2  2]]\n",
      "Precision: 0.2222\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[85  7]\n",
      " [ 9  3]]\n",
      "Precision: 0.3000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2727\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[95  2]\n",
      " [ 7  0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[103   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[93  3]\n",
      " [ 7  1]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[72 10]\n",
      " [ 9 13]]\n",
      "Precision: 0.5652\n",
      "Recall: 0.5909\n",
      "F1 Score: 0.5778\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[102   1]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Evaluation results for cc dataset:\n",
      "eval_loss: 1.6128\n",
      "eval_accuracy: 0.5481\n",
      "eval_f1: 0.5933\n",
      "eval_precision: 0.5221\n",
      "eval_recall: 0.5481\n",
      "eval_confusion_matrix: {'Class_0': [[50, 14], [5, 35]], 'Class_1': [[103, 0], [1, 0]], 'Class_3': [[94, 2], [5, 3]], 'Class_4': [[93, 7], [2, 2]], 'Class_5': [[85, 7], [9, 3]], 'Class_6': [[95, 2], [7, 0]], 'Class_7': [[103, 0], [1, 0]], 'Class_8': [[93, 3], [7, 1]], 'Class_9': [[72, 10], [9, 13]], 'Class_10': [[102, 1], [1, 0]]}\n",
      "eval_runtime: 27.0088\n",
      "eval_samples_per_second: 3.8510\n",
      "eval_steps_per_second: 0.9630\n",
      "epoch: 3.0000\n",
      "\n",
      "Saving cc model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-01-21 13:56:17,667 - ERROR - Error in debugging misclassifications: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in CC training: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1941/2645010921.py\", line 91, in train_cc\n",
      "    cc_results, cc_model, cc_tokenizer, cc_label_mapping = train_single_dataset(\n",
      "  File \"/tmp/ipykernel_1941/2084970581.py\", line 56, in train_single_dataset\n",
      "    misclass_df = debug_misclassifications(df, model, tokenizer, label_mapping)\n",
      "  File \"/teamspace/studios/this_studio/nlp_Backpropagandists_2024/code/modules/utils.py\", line 126, in debug_misclassifications\n",
      "    outputs = model(input_ids, attention_mask=attention_mask)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/peft_model.py\", line 1521, in forward\n",
      "    return self.base_model(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 1251, in forward\n",
      "    transformer_outputs = self.model(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 859, in forward\n",
      "    inputs_embeds = self.embed_tokens(input_ids)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1561, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\n",
      "    return F.embedding(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py\", line 2237, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.54808</td></tr><tr><td>eval/f1</td><td>0.59328</td></tr><tr><td>eval/loss</td><td>1.61278</td></tr><tr><td>eval/precision</td><td>0.52207</td></tr><tr><td>eval/recall</td><td>0.54808</td></tr><tr><td>eval/runtime</td><td>27.0088</td></tr><tr><td>eval/samples_per_second</td><td>3.851</td></tr><tr><td>eval/steps_per_second</td><td>0.963</td></tr><tr><td>total_flos</td><td>2.483391893078016e+16</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>156</td></tr><tr><td>train/grad_norm</td><td>6.19319</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1479</td></tr><tr><td>train_loss</td><td>1.35524</td></tr><tr><td>train_runtime</td><td>996.167</td></tr><tr><td>train_samples_per_second</td><td>1.25</td></tr><tr><td>train_steps_per_second</td><td>0.157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">llama-classification-cc-20250121</strong> at: <a href='https://wandb.ai/backpropagandists/llama-classification/runs/9904jlz8' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification/runs/9904jlz8</a><br> View project at: <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250121_133349-9904jlz8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cc_results, cc_model, cc_tokenizer, cc_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 91\u001b[0m, in \u001b[0;36mtrain_cc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     config \u001b[38;5;241m=\u001b[39m setup_training()\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting CC dataset training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m     cc_results, cc_model, cc_tokenizer, cc_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_normalized_cc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cc_results, cc_model, cc_tokenizer, cc_label_mapping\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mtrain_single_dataset\u001b[0;34m(df, model_name, output_dir, current_date, dataset_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(dataset_output_dir)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Debug misclassifications\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m misclass_df \u001b[38;5;241m=\u001b[39m \u001b[43mdebug_misclassifications\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# End wandb run\u001b[39;00m\n\u001b[1;32m     59\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/nlp_Backpropagandists_2024/code/modules/utils.py:126\u001b[0m, in \u001b[0;36mdebug_misclassifications\u001b[0;34m(dataset, model, tokenizer, label_mapping, dataset_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 126\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Process misclassifications\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/peft_model.py:1521\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1520\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1251\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1251\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1263\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:859\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    856\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# kept for BC (non `Cache` `past_key_values` inputs)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "cc_results, cc_model, cc_tokenizer, cc_label_mapping = train_cc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device: NVIDIA L40S\n",
      "GPU Memory: 47.81 GB\n",
      "\n",
      "Loading datasets...\n",
      "Repository root: /teamspace/studios/this_studio/nlp_Backpropagandists_2024\n",
      "Looking for data files in: /teamspace/studios/this_studio/nlp_Backpropagandists_2024/code\n",
      "\n",
      "Starting full dataset training...\n",
      "\n",
      "Training on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonaskruse\u001b[0m (\u001b[33mbackpropagandists\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/nlp_Backpropagandists_2024/code/dl_methods/llama/wandb/run-20250121_135854-1ysi3t05</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/backpropagandists/llama-classification/runs/1ysi3t05' target=\"_blank\">llama-classification-full-20250121</a></strong> to <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/backpropagandists/llama-classification/runs/1ysi3t05' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification/runs/1ysi3t05</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating narrative mapping...\n",
      "Number of unique narratives: 21\n",
      "\n",
      "Sample narrative mappings:\n",
      "0: Amplifying Climate Fears\n",
      "1: Amplifying war-related fears\n",
      "2: Blaming the war on others rather than the invader\n",
      "3: Climate change is beneficial\n",
      "4: Controversy about green technologies\n",
      "\n",
      "Training set size: 1355\n",
      "Validation set size: 339\n",
      "\n",
      "Initializing tokenizer...\n",
      "\n",
      "Tokenizing texts...\n",
      "\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 13:59:01,940 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1bdb6782ea47d2a9d012a8ef40d917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at openlm-research/open_llama_7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,863,232 || all params: 6,624,292,864 || trainable%: 0.2546\n",
      "\n",
      "Starting classification head pre-training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 17:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.342200</td>\n",
       "      <td>2.502463</td>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.441706</td>\n",
       "      <td>0.247929</td>\n",
       "      <td>0.247788</td>\n",
       "      <td>{'Class_0': [[266, 37], [14, 22]], 'Class_1': [[307, 9], [22, 1]], 'Class_2': [[312, 10], [17, 0]], 'Class_4': [[338, 0], [1, 0]], 'Class_5': [[334, 1], [4, 0]], 'Class_6': [[327, 9], [3, 0]], 'Class_7': [[308, 10], [20, 1]], 'Class_8': [[226, 63], [27, 23]], 'Class_9': [[288, 15], [36, 0]], 'Class_10': [[334, 0], [5, 0]], 'Class_11': [[333, 2], [4, 0]], 'Class_13': [[330, 2], [6, 1]], 'Class_14': [[333, 0], [6, 0]], 'Class_15': [[218, 63], [28, 30]], 'Class_16': [[335, 1], [3, 0]], 'Class_17': [[275, 29], [29, 6]], 'Class_18': [[336, 2], [1, 0]], 'Class_19': [[325, 0], [14, 0]], 'Class_20': [[322, 2], [15, 0]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[266  37]\n",
      " [ 14  22]]\n",
      "Precision: 0.3729\n",
      "Recall: 0.6111\n",
      "F1 Score: 0.4632\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[307   9]\n",
      " [ 22   1]]\n",
      "Precision: 0.1000\n",
      "Recall: 0.0435\n",
      "F1 Score: 0.0606\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[312  10]\n",
      " [ 17   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[338   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[334   1]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[327   9]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[308  10]\n",
      " [ 20   1]]\n",
      "Precision: 0.0909\n",
      "Recall: 0.0476\n",
      "F1 Score: 0.0625\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[226  63]\n",
      " [ 27  23]]\n",
      "Precision: 0.2674\n",
      "Recall: 0.4600\n",
      "F1 Score: 0.3382\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[288  15]\n",
      " [ 36   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[334   0]\n",
      " [  5   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[333   2]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 13:\n",
      "Confusion Matrix:\n",
      "[[330   2]\n",
      " [  6   1]]\n",
      "Precision: 0.3333\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2000\n",
      "\n",
      "Metrics for Class 14:\n",
      "Confusion Matrix:\n",
      "[[333   0]\n",
      " [  6   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 15:\n",
      "Confusion Matrix:\n",
      "[[218  63]\n",
      " [ 28  30]]\n",
      "Precision: 0.3226\n",
      "Recall: 0.5172\n",
      "F1 Score: 0.3974\n",
      "\n",
      "Metrics for Class 16:\n",
      "Confusion Matrix:\n",
      "[[335   1]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 17:\n",
      "Confusion Matrix:\n",
      "[[275  29]\n",
      " [ 29   6]]\n",
      "Precision: 0.1714\n",
      "Recall: 0.1714\n",
      "F1 Score: 0.1714\n",
      "\n",
      "Metrics for Class 18:\n",
      "Confusion Matrix:\n",
      "[[336   2]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 19:\n",
      "Confusion Matrix:\n",
      "[[325   0]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 20:\n",
      "Confusion Matrix:\n",
      "[[322   2]\n",
      " [ 15   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unfreezing LoRA adapters for full training...\n",
      "\n",
      "Starting full model fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='507' max='507' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [507/507 53:53, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.872200</td>\n",
       "      <td>2.294061</td>\n",
       "      <td>0.315634</td>\n",
       "      <td>0.430827</td>\n",
       "      <td>0.306476</td>\n",
       "      <td>0.315634</td>\n",
       "      <td>{'Class_0': [[281, 22], [6, 30]], 'Class_1': [[287, 29], [15, 8]], 'Class_2': [[318, 4], [17, 0]], 'Class_4': [[338, 0], [1, 0]], 'Class_5': [[324, 11], [4, 0]], 'Class_6': [[336, 0], [3, 0]], 'Class_7': [[315, 3], [19, 2]], 'Class_8': [[224, 65], [24, 26]], 'Class_9': [[291, 12], [32, 4]], 'Class_10': [[334, 0], [5, 0]], 'Class_11': [[334, 1], [4, 0]], 'Class_13': [[329, 3], [6, 1]], 'Class_14': [[333, 0], [5, 1]], 'Class_15': [[232, 49], [27, 31]], 'Class_16': [[336, 0], [3, 0]], 'Class_17': [[275, 29], [31, 4]], 'Class_18': [[336, 2], [1, 0]], 'Class_19': [[324, 1], [14, 0]], 'Class_20': [[323, 1], [15, 0]]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>2.776076</td>\n",
       "      <td>0.324484</td>\n",
       "      <td>0.365485</td>\n",
       "      <td>0.318175</td>\n",
       "      <td>0.324484</td>\n",
       "      <td>{'Class_0': [[291, 12], [6, 30]], 'Class_1': [[298, 18], [18, 5]], 'Class_2': [[313, 9], [16, 1]], 'Class_4': [[338, 0], [1, 0]], 'Class_5': [[332, 3], [4, 0]], 'Class_6': [[330, 6], [3, 0]], 'Class_7': [[313, 5], [19, 2]], 'Class_8': [[256, 33], [33, 17]], 'Class_9': [[260, 43], [26, 10]], 'Class_10': [[334, 0], [5, 0]], 'Class_11': [[333, 2], [4, 0]], 'Class_13': [[330, 2], [5, 2]], 'Class_14': [[329, 4], [6, 0]], 'Class_15': [[228, 53], [26, 32]], 'Class_16': [[335, 1], [3, 0]], 'Class_17': [[282, 22], [27, 8]], 'Class_18': [[336, 2], [1, 0]], 'Class_19': [[318, 7], [12, 2]], 'Class_20': [[317, 7], [14, 1]]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[281  22]\n",
      " [  6  30]]\n",
      "Precision: 0.5769\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.6818\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[287  29]\n",
      " [ 15   8]]\n",
      "Precision: 0.2162\n",
      "Recall: 0.3478\n",
      "F1 Score: 0.2667\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[318   4]\n",
      " [ 17   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[338   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[324  11]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[336   0]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[315   3]\n",
      " [ 19   2]]\n",
      "Precision: 0.4000\n",
      "Recall: 0.0952\n",
      "F1 Score: 0.1538\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[224  65]\n",
      " [ 24  26]]\n",
      "Precision: 0.2857\n",
      "Recall: 0.5200\n",
      "F1 Score: 0.3688\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[291  12]\n",
      " [ 32   4]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1111\n",
      "F1 Score: 0.1538\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[334   0]\n",
      " [  5   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[334   1]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 13:\n",
      "Confusion Matrix:\n",
      "[[329   3]\n",
      " [  6   1]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Metrics for Class 14:\n",
      "Confusion Matrix:\n",
      "[[333   0]\n",
      " [  5   1]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.2857\n",
      "\n",
      "Metrics for Class 15:\n",
      "Confusion Matrix:\n",
      "[[232  49]\n",
      " [ 27  31]]\n",
      "Precision: 0.3875\n",
      "Recall: 0.5345\n",
      "F1 Score: 0.4493\n",
      "\n",
      "Metrics for Class 16:\n",
      "Confusion Matrix:\n",
      "[[336   0]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 17:\n",
      "Confusion Matrix:\n",
      "[[275  29]\n",
      " [ 31   4]]\n",
      "Precision: 0.1212\n",
      "Recall: 0.1143\n",
      "F1 Score: 0.1176\n",
      "\n",
      "Metrics for Class 18:\n",
      "Confusion Matrix:\n",
      "[[336   2]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 19:\n",
      "Confusion Matrix:\n",
      "[[324   1]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 20:\n",
      "Confusion Matrix:\n",
      "[[323   1]\n",
      " [ 15   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[286  17]\n",
      " [  7  29]]\n",
      "Precision: 0.6304\n",
      "Recall: 0.8056\n",
      "F1 Score: 0.7073\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[303  13]\n",
      " [ 19   4]]\n",
      "Precision: 0.2353\n",
      "Recall: 0.1739\n",
      "F1 Score: 0.2000\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[315   7]\n",
      " [ 16   1]]\n",
      "Precision: 0.1250\n",
      "Recall: 0.0588\n",
      "F1 Score: 0.0800\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[338   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[331   4]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[331   5]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[311   7]\n",
      " [ 14   7]]\n",
      "Precision: 0.5000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[231  58]\n",
      " [ 25  25]]\n",
      "Precision: 0.3012\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.3759\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[285  18]\n",
      " [ 29   7]]\n",
      "Precision: 0.2800\n",
      "Recall: 0.1944\n",
      "F1 Score: 0.2295\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[332   2]\n",
      " [  5   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[332   3]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 13:\n",
      "Confusion Matrix:\n",
      "[[327   5]\n",
      " [  5   2]]\n",
      "Precision: 0.2857\n",
      "Recall: 0.2857\n",
      "F1 Score: 0.2857\n",
      "\n",
      "Metrics for Class 14:\n",
      "Confusion Matrix:\n",
      "[[327   6]\n",
      " [  6   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 15:\n",
      "Confusion Matrix:\n",
      "[[253  28]\n",
      " [ 35  23]]\n",
      "Precision: 0.4510\n",
      "Recall: 0.3966\n",
      "F1 Score: 0.4220\n",
      "\n",
      "Metrics for Class 16:\n",
      "Confusion Matrix:\n",
      "[[334   2]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 17:\n",
      "Confusion Matrix:\n",
      "[[262  42]\n",
      " [ 26   9]]\n",
      "Precision: 0.1765\n",
      "Recall: 0.2571\n",
      "F1 Score: 0.2093\n",
      "\n",
      "Metrics for Class 18:\n",
      "Confusion Matrix:\n",
      "[[335   3]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 19:\n",
      "Confusion Matrix:\n",
      "[[321   4]\n",
      " [ 13   1]]\n",
      "Precision: 0.2000\n",
      "Recall: 0.0714\n",
      "F1 Score: 0.1053\n",
      "\n",
      "Metrics for Class 20:\n",
      "Confusion Matrix:\n",
      "[[317   7]\n",
      " [ 15   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[291  12]\n",
      " [  6  30]]\n",
      "Precision: 0.7143\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.7692\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[298  18]\n",
      " [ 18   5]]\n",
      "Precision: 0.2174\n",
      "Recall: 0.2174\n",
      "F1 Score: 0.2174\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[313   9]\n",
      " [ 16   1]]\n",
      "Precision: 0.1000\n",
      "Recall: 0.0588\n",
      "F1 Score: 0.0741\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[338   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[332   3]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[330   6]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[313   5]\n",
      " [ 19   2]]\n",
      "Precision: 0.2857\n",
      "Recall: 0.0952\n",
      "F1 Score: 0.1429\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[256  33]\n",
      " [ 33  17]]\n",
      "Precision: 0.3400\n",
      "Recall: 0.3400\n",
      "F1 Score: 0.3400\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[260  43]\n",
      " [ 26  10]]\n",
      "Precision: 0.1887\n",
      "Recall: 0.2778\n",
      "F1 Score: 0.2247\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[334   0]\n",
      " [  5   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[333   2]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 13:\n",
      "Confusion Matrix:\n",
      "[[330   2]\n",
      " [  5   2]]\n",
      "Precision: 0.5000\n",
      "Recall: 0.2857\n",
      "F1 Score: 0.3636\n",
      "\n",
      "Metrics for Class 14:\n",
      "Confusion Matrix:\n",
      "[[329   4]\n",
      " [  6   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 15:\n",
      "Confusion Matrix:\n",
      "[[228  53]\n",
      " [ 26  32]]\n",
      "Precision: 0.3765\n",
      "Recall: 0.5517\n",
      "F1 Score: 0.4476\n",
      "\n",
      "Metrics for Class 16:\n",
      "Confusion Matrix:\n",
      "[[335   1]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 17:\n",
      "Confusion Matrix:\n",
      "[[282  22]\n",
      " [ 27   8]]\n",
      "Precision: 0.2667\n",
      "Recall: 0.2286\n",
      "F1 Score: 0.2462\n",
      "\n",
      "Metrics for Class 18:\n",
      "Confusion Matrix:\n",
      "[[336   2]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 19:\n",
      "Confusion Matrix:\n",
      "[[318   7]\n",
      " [ 12   2]]\n",
      "Precision: 0.2222\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.1739\n",
      "\n",
      "Metrics for Class 20:\n",
      "Confusion Matrix:\n",
      "[[317   7]\n",
      " [ 14   1]]\n",
      "Precision: 0.1250\n",
      "Recall: 0.0667\n",
      "F1 Score: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 01:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Class 0:\n",
      "Confusion Matrix:\n",
      "[[281  22]\n",
      " [  6  30]]\n",
      "Precision: 0.5769\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.6818\n",
      "\n",
      "Metrics for Class 1:\n",
      "Confusion Matrix:\n",
      "[[287  29]\n",
      " [ 15   8]]\n",
      "Precision: 0.2162\n",
      "Recall: 0.3478\n",
      "F1 Score: 0.2667\n",
      "\n",
      "Metrics for Class 2:\n",
      "Confusion Matrix:\n",
      "[[318   4]\n",
      " [ 17   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 4:\n",
      "Confusion Matrix:\n",
      "[[338   0]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 5:\n",
      "Confusion Matrix:\n",
      "[[324  11]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 6:\n",
      "Confusion Matrix:\n",
      "[[336   0]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 7:\n",
      "Confusion Matrix:\n",
      "[[315   3]\n",
      " [ 19   2]]\n",
      "Precision: 0.4000\n",
      "Recall: 0.0952\n",
      "F1 Score: 0.1538\n",
      "\n",
      "Metrics for Class 8:\n",
      "Confusion Matrix:\n",
      "[[224  65]\n",
      " [ 24  26]]\n",
      "Precision: 0.2857\n",
      "Recall: 0.5200\n",
      "F1 Score: 0.3688\n",
      "\n",
      "Metrics for Class 9:\n",
      "Confusion Matrix:\n",
      "[[291  12]\n",
      " [ 32   4]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1111\n",
      "F1 Score: 0.1538\n",
      "\n",
      "Metrics for Class 10:\n",
      "Confusion Matrix:\n",
      "[[334   0]\n",
      " [  5   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 11:\n",
      "Confusion Matrix:\n",
      "[[334   1]\n",
      " [  4   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 13:\n",
      "Confusion Matrix:\n",
      "[[329   3]\n",
      " [  6   1]]\n",
      "Precision: 0.2500\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Metrics for Class 14:\n",
      "Confusion Matrix:\n",
      "[[333   0]\n",
      " [  5   1]]\n",
      "Precision: 1.0000\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.2857\n",
      "\n",
      "Metrics for Class 15:\n",
      "Confusion Matrix:\n",
      "[[232  49]\n",
      " [ 27  31]]\n",
      "Precision: 0.3875\n",
      "Recall: 0.5345\n",
      "F1 Score: 0.4493\n",
      "\n",
      "Metrics for Class 16:\n",
      "Confusion Matrix:\n",
      "[[336   0]\n",
      " [  3   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 17:\n",
      "Confusion Matrix:\n",
      "[[275  29]\n",
      " [ 31   4]]\n",
      "Precision: 0.1212\n",
      "Recall: 0.1143\n",
      "F1 Score: 0.1176\n",
      "\n",
      "Metrics for Class 18:\n",
      "Confusion Matrix:\n",
      "[[336   2]\n",
      " [  1   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 19:\n",
      "Confusion Matrix:\n",
      "[[324   1]\n",
      " [ 14   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Metrics for Class 20:\n",
      "Confusion Matrix:\n",
      "[[323   1]\n",
      " [ 15   0]]\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Evaluation results for full dataset:\n",
      "eval_loss: 2.2941\n",
      "eval_accuracy: 0.3156\n",
      "eval_f1: 0.4308\n",
      "eval_precision: 0.3065\n",
      "eval_recall: 0.3156\n",
      "eval_confusion_matrix: {'Class_0': [[281, 22], [6, 30]], 'Class_1': [[287, 29], [15, 8]], 'Class_2': [[318, 4], [17, 0]], 'Class_4': [[338, 0], [1, 0]], 'Class_5': [[324, 11], [4, 0]], 'Class_6': [[336, 0], [3, 0]], 'Class_7': [[315, 3], [19, 2]], 'Class_8': [[224, 65], [24, 26]], 'Class_9': [[291, 12], [32, 4]], 'Class_10': [[334, 0], [5, 0]], 'Class_11': [[334, 1], [4, 0]], 'Class_13': [[329, 3], [6, 1]], 'Class_14': [[333, 0], [5, 1]], 'Class_15': [[232, 49], [27, 31]], 'Class_16': [[336, 0], [3, 0]], 'Class_17': [[275, 29], [31, 4]], 'Class_18': [[336, 2], [1, 0]], 'Class_19': [[324, 1], [14, 0]], 'Class_20': [[323, 1], [15, 0]]}\n",
      "eval_runtime: 86.7013\n",
      "eval_samples_per_second: 3.9100\n",
      "eval_steps_per_second: 0.9800\n",
      "epoch: 2.9853\n",
      "\n",
      "Saving full model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-01-21 15:12:29,904 - ERROR - Error in debugging misclassifications: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in full dataset training: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_82240/2645010921.py\", line 115, in train_full\n",
      "    results, model, tokenizer, label_mapping = train_single_dataset(\n",
      "  File \"/tmp/ipykernel_82240/2084970581.py\", line 56, in train_single_dataset\n",
      "    misclass_df = debug_misclassifications(df, model, tokenizer, label_mapping)\n",
      "  File \"/teamspace/studios/this_studio/nlp_Backpropagandists_2024/code/modules/utils.py\", line 126, in debug_misclassifications\n",
      "    outputs = model(input_ids, attention_mask=attention_mask)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/peft_model.py\", line 1521, in forward\n",
      "    return self.base_model(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 1251, in forward\n",
      "    transformer_outputs = self.model(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 859, in forward\n",
      "    inputs_embeds = self.embed_tokens(input_ids)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1561, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\n",
      "    return F.embedding(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py\", line 2237, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.31563</td></tr><tr><td>eval/f1</td><td>0.43083</td></tr><tr><td>eval/loss</td><td>2.29406</td></tr><tr><td>eval/precision</td><td>0.30648</td></tr><tr><td>eval/recall</td><td>0.31563</td></tr><tr><td>eval/runtime</td><td>86.7013</td></tr><tr><td>eval/samples_per_second</td><td>3.91</td></tr><tr><td>eval/steps_per_second</td><td>0.98</td></tr><tr><td>total_flos</td><td>8.070626800356557e+16</td></tr><tr><td>train/epoch</td><td>2.98525</td></tr><tr><td>train/global_step</td><td>507</td></tr><tr><td>train/grad_norm</td><td>18.78744</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6345</td></tr><tr><td>train_loss</td><td>1.85357</td></tr><tr><td>train_runtime</td><td>3239.531</td></tr><tr><td>train_samples_per_second</td><td>1.255</td></tr><tr><td>train_steps_per_second</td><td>0.157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">llama-classification-full-20250121</strong> at: <a href='https://wandb.ai/backpropagandists/llama-classification/runs/1ysi3t05' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification/runs/1ysi3t05</a><br> View project at: <a href='https://wandb.ai/backpropagandists/llama-classification' target=\"_blank\">https://wandb.ai/backpropagandists/llama-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250121_135854-1ysi3t05/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train full dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results, model, tokenizer, label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m, in \u001b[0;36mtrain_full\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     config \u001b[38;5;241m=\u001b[39m setup_training()\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting full dataset training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m     results, model, tokenizer, label_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_normalized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, model, tokenizer, label_mapping\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[2], line 56\u001b[0m, in \u001b[0;36mtrain_single_dataset\u001b[0;34m(df, model_name, output_dir, current_date, dataset_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(dataset_output_dir)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Debug misclassifications\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m misclass_df \u001b[38;5;241m=\u001b[39m \u001b[43mdebug_misclassifications\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# End wandb run\u001b[39;00m\n\u001b[1;32m     59\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/nlp_Backpropagandists_2024/code/modules/utils.py:126\u001b[0m, in \u001b[0;36mdebug_misclassifications\u001b[0;34m(dataset, model, tokenizer, label_mapping, dataset_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 126\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Process misclassifications\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/peft_model.py:1521\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1520\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1251\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1251\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1263\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:859\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    856\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# kept for BC (non `Cache` `past_key_values` inputs)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Train full dataset\n",
    "results, model, tokenizer, label_mapping = train_full()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
