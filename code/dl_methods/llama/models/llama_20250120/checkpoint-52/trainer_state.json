{
  "best_metric": 1.6311976909637451,
  "best_model_checkpoint": "C:\\Users\\krona\\OneDrive - TU Wien\\TU Wien\\1. Semester\\NLP\\nlp_Backpropagandists_2024\\code\\dl_methods\\llama\\models\\llama_20250120\\checkpoint-52",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 52,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 12.380439758300781,
      "learning_rate": 0.00019337748344370862,
      "loss": 0.8547,
      "step": 10
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 11.493407249450684,
      "learning_rate": 0.00018013245033112585,
      "loss": 0.8814,
      "step": 20
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 13.885804176330566,
      "learning_rate": 0.00016688741721854306,
      "loss": 1.1829,
      "step": 30
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 22.081567764282227,
      "learning_rate": 0.00015364238410596029,
      "loss": 1.725,
      "step": 40
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 17.087263107299805,
      "learning_rate": 0.0001403973509933775,
      "loss": 1.3873,
      "step": 50
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5288461538461539,
      "eval_confusion_matrix": {
        "Class_0": [
          [
            41,
            23
          ],
          [
            1,
            39
          ]
        ],
        "Class_1": [
          [
            103,
            0
          ],
          [
            1,
            0
          ]
        ],
        "Class_10": [
          [
            103,
            0
          ],
          [
            1,
            0
          ]
        ],
        "Class_3": [
          [
            94,
            2
          ],
          [
            6,
            2
          ]
        ],
        "Class_4": [
          [
            100,
            0
          ],
          [
            4,
            0
          ]
        ],
        "Class_5": [
          [
            81,
            11
          ],
          [
            10,
            2
          ]
        ],
        "Class_6": [
          [
            95,
            2
          ],
          [
            7,
            0
          ]
        ],
        "Class_7": [
          [
            103,
            0
          ],
          [
            1,
            0
          ]
        ],
        "Class_8": [
          [
            96,
            0
          ],
          [
            7,
            1
          ]
        ],
        "Class_9": [
          [
            71,
            11
          ],
          [
            11,
            11
          ]
        ]
      },
      "eval_f1": 0.5288461538461539,
      "eval_loss": 1.6311976909637451,
      "eval_precision": 0.5288461538461539,
      "eval_recall": 0.5288461538461539,
      "eval_runtime": 84.4647,
      "eval_samples_per_second": 1.231,
      "eval_steps_per_second": 0.308,
      "step": 52
    }
  ],
  "logging_steps": 10,
  "max_steps": 156,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8277972976926720.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
