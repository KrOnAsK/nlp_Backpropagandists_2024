{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# All Datasets\n",
    "\n",
    "2024-12-15 11:07:06,687 - __main__ - INFO - BERT training on full data completed. Results: {'eval_loss': 2.1668293476104736, 'eval_accuracy': 0.5135135135135135, 'eval_f1': 0.5135135135135135, 'eval_precision': 0.5135135135135135, 'eval_recall': 0.5135135135135135, 'eval_runtime': 23.7996, 'eval_samples_per_second': 1.555, 'eval_steps_per_second': 0.21, 'epoch': 5.0}\n",
    "\n",
    "================================================================================\n",
    "                               PROCESSING SUMMARY\n",
    "================================================================================\n",
    "\n",
    "GENERAL INFORMATION\n",
    "--------------------------------------------------------------------------------\n",
    "Total Processing Time: 38m 59s\n",
    "Steps Completed: 4\n",
    "\n",
    "DOCUMENT STATISTICS\n",
    "--------------------------------------------------------------------------------\n",
    "Total Documents: 198\n",
    "Ua Documents: 126\n",
    "Cc Documents: 72\n",
    "Average Tokens Per Doc: 20.47\n",
    "\n",
    "PROCESSING TIMELINE\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "[10:28:07] Data Loading\n",
    "  └─ document_count: 198\n",
    "\n",
    "[10:28:07] Text Tokenization\n",
    "\n",
    "[10:28:07] Unusual Sentence Handling\n",
    "\n",
    "[10:28:24] Text Normalization\n",
    "  └─ total_documents: 198\n",
    "  └─ ua_documents: 126\n",
    "  └─ cc_documents: 72\n",
    "\n",
    "ML RESULTS\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "BERT (Full Dataset):\n",
    "  └─ eval_loss: 2.1668\n",
    "  └─ eval_accuracy: 0.5135\n",
    "  └─ eval_f1: 0.5135\n",
    "  └─ eval_precision: 0.5135\n",
    "  └─ eval_recall: 0.5135\n",
    "  └─ eval_runtime: 23.7996\n",
    "  └─ eval_samples_per_second: 1.5550\n",
    "  └─ eval_steps_per_second: 0.2100\n",
    "  └─ epoch: 5.0000\n",
    "\n",
    "================================================================================\n",
    "\n",
    "\n",
    "Process finished with exit code 0"
   ],
   "id": "1e1279e9bd9a9583"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ONLY CC:\n",
    "\n",
    "BERT (CC Dataset):\n",
    "  └─ eval_loss: 1.0816\n",
    "  └─ eval_accuracy: 0.7143\n",
    "  └─ eval_f1: 0.7143\n",
    "  └─ eval_precision: 0.7143\n",
    "  └─ eval_recall: 0.7143\n",
    "  └─ eval_confusion_matrix: {'Class_0': [[13, 0], [1, 0]], 'Class_3': [[13, 0], [1, 0]], 'Class_4': [[13, 0], [1, 0]], 'Class_5': [[0, 4], [0, 10]], 'Class_6': [[13, 0], [1, 0]]}\n",
    "  └─ eval_runtime: 7.3304\n",
    "  └─ eval_samples_per_second: 1.9100\n",
    "  └─ eval_steps_per_second: 0.2730\n",
    "  └─ epoch: 5.0000"
   ],
   "id": "655cc4f04dc8f70f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ONLY UW:\n",
    "BERT (UA Dataset):\n",
    "  └─ eval_loss: 2.3757\n",
    "  └─ eval_accuracy: 0.4167\n",
    "  └─ eval_f1: 0.4167\n",
    "  └─ eval_precision: 0.4167\n",
    "  └─ eval_recall: 0.4167\n",
    "  └─ eval_confusion_matrix: {'Class_1': [[23, 0], [1, 0]], 'Class_2': [[23, 0], [1, 0]], 'Class_3': [[23, 0], [1, 0]], 'Class_4': [[23, 0], [1, 0]], 'Class_6': [[23, 0], [1, 0]], 'Class_7': [[23, 0], [1, 0]], 'Class_8': [[23, 0], [1, 0]], 'Class_9': [[23, 0], [1, 0]], 'Class_10': [[23, 0], [1, 0]], 'Class_11': [[23, 0], [1, 0]], 'Class_13': [[23, 0], [1, 0]], 'Class_14': [[0, 14], [0, 10]], 'Class_15': [[23, 0], [1, 0]], 'Class_17': [[23, 0], [1, 0]], 'Class_18': [[23, 0], [1, 0]]}\n",
    "  └─ eval_runtime: 13.0949\n",
    "  └─ eval_samples_per_second: 1.8330\n",
    "  └─ eval_steps_per_second: 0.2290\n",
    "  └─ epoch: 5.0000"
   ],
   "id": "829a2b432ba50f40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "91eb49c383f14305"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Description of Deep Leaning baseline and used methods\n",
    "\n",
    "As Deep Learning model we used BERT. We have trained the model using labeled data and measured the performance of the model using the following metrics:\n",
    "* Accuracy\n",
    "* Recall,\n",
    "* Precision\n",
    "* F1 Score\n",
    "\n",
    "Before training the model, we have normalized and tokenized the data. To train the model, it is also necessary to create a label mapping of each unique class label.\n",
    "For splitting, we used a 70%/ 30% approach.\n",
    "By splitting the narratives, we followed different approaches to be able to evaluate the differences between them.\n",
    "* Not splitting between Ukraine War and Climate Change\n",
    "* Splitting narratives into two dataframes, containing only Ukraine War narratives or only Climate Change narratives each."
   ],
   "id": "f3dc750d8a613b7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50d900a1b5772728"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis\n",
    "\n",
    "When the narratives were split by topic, the metrics for Climate Change improved, while the metrics for the Ukraine War worsened.\n",
    "Having all metrics of 0.5135 during the approach with all dataframes at the same time, it is a moderate performance.\n",
    "\n",
    "After that, we used only Climate Change narratives and all resulting metrics got much better: 0.7143.\n",
    "Using only Ukraine War narratives, we received 0.4167 for all metrics, which is the worst result, although it is the highest amount of narratives that we had for training.\n",
    "\n",
    "## Analyzing single classes\n",
    "\n",
    "To be able to analyze differences in prediction of different classes, we analyzed the confusion matrices for each class individually.\n",
    "\n",
    "For all three approaches, we received the same result for the confusion matrix of the class *Other*. For all approaches, the model predicted class \"Other\" correctly as positive. It also predicted other classes to be from class *Other*.\n",
    "\n",
    "### Climate Change\n",
    "\n",
    "For Climate Change narratives, we received for class *Other* the following Confusion Matrix:\n",
    "[[0, 4], [0, 10]]\n",
    "\n",
    "Calculating the metrics for this specific class:\n",
    "* Accuracy: 71,43 %\n",
    "* Precision: 71,43 %\n",
    "* Recall: 100%\n",
    "* F1 Score: 83,33 %\n",
    "\n",
    "For all other classes, we received the following equal Confusion Matrix:\n",
    "[[13, 0], [1, 0]]\n",
    "* Accuracy: 92,86 %\n",
    "* Precision: 0 %\n",
    "* Recall: 0%\n",
    "* F1 Score: 0 %\n",
    "\n",
    "\n",
    "### Ukraine War\n",
    "\n",
    "For Ukraine War narratives, we received for class *Other* the following Confusion Matrix:\n",
    "[[0, 14], [0, 10]]\n",
    "\n",
    "Calculating the metrics for this specific class:\n",
    "* Accuracy: 41,7 %\n",
    "* Precision: 41,7 %\n",
    "* Recall: 100%\n",
    "* F1 Score: 58,8%\n",
    "\n",
    "For all other classes, we received the following equal Confusion Matrix:\n",
    "[[23, 0], [1, 0]]\n",
    "* Accuracy: 95,8%\n",
    "* Precision: 0%\n",
    "* Recall: 0%\n",
    "* F1 Score: 0%\n",
    "\n",
    "\n",
    "### Inspection of noticeable narratives\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7bda38090a25c161"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3fc555b627558abd"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
